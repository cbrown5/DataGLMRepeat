{
    "data" : [
        "                      fitted = predict(model[[1]])[,1],",
        "+ ",
        "                      #Note Mean estimate is in col 1 of ",
        "+ ",
        "                      #brms predict",
        "+ ",
        "                      resid = ds_resids(dat$y, ",
        "+ ",
        "                                        predict(model[[1]])[,1], ",
        "+ ",
        "                                        plot = FALSE))",
        "+ ",
        "    g1 <- ggplot(dsdf) + ",
        "+ ",
        "      aes(x = fitted, y = resid, color = x2) + ",
        "+ ",
        "      geom_point()  +",
        "+ ",
        "      ggtitle(form)",
        "+ ",
        "    #save result ",
        "+ ",
        "    # ggsave(g1, file = paste0(\"model-\", ID, \".png\"))",
        "+ ",
        "    list(g1)",
        "+ ",
        "  })",
        "> ",
        "dsplots[[1]]",
        "[[1]]\n\n",
        "> ",
        "?paste",
        "> ",
        "?paste",
        "> ",
        "?paste",
        "> ",
        "#' Paste with a dash ",
        "> ",
        "#'",
        "> ",
        "#' @Usage paste_(...)",
        "> ",
        "#'",
        "> ",
        "#' @param ... one or more R objects to convert to characters",
        "> ",
        "#'",
        "> ",
        "#' @return A string ",
        "> ",
        "#' @Details shortcut for paste(\"a\", \"b\", sep =\"-\")",
        "> ",
        "#'  ",
        "> ",
        "#' @author Christopher J. Brown",
        "> ",
        "#' @rdname paste_",
        "> ",
        "#' @export",
        "> ",
        "",
        "> ",
        "paste_ <- function(...){",
        "+ ",
        "  paste(..., sep = \"-\")",
        "+ ",
        "}",
        "> ",
        "dsplots <- dout %>%",
        "+ ",
        "  group_by(ID) %>%",
        "+ ",
        "  with_groups({",
        "+ ",
        "    dsdf <- bind_cols(dat, ",
        "+ ",
        "                      fitted = predict(model[[1]])[,1],",
        "+ ",
        "                      #Note Mean estimate is in col 1 of ",
        "+ ",
        "                      #brms predict",
        "+ ",
        "                      resid = ds_resids(dat$y, ",
        "+ ",
        "                                        predict(model[[1]])[,1], ",
        "+ ",
        "                                        plot = FALSE))",
        "+ ",
        "    g1 <- ggplot(dsdf) + ",
        "+ ",
        "      aes(x = fitted, y = resid, color = x2) + ",
        "+ ",
        "      geom_point()  +",
        "+ ",
        "      ggtitle(paste_(form, family, prior))",
        "+ ",
        "    #save plot to file ",
        "+ ",
        "    # ggsave(g1, file = paste0(\"figures/model-\", ID, \".png\"))",
        "+ ",
        "    list(g1)",
        "+ ",
        "  })",
        "> ",
        "dsplots[[1]]",
        "[[1]]\n\n",
        "> ",
        "#' Paste with a dash ",
        "> ",
        "#'",
        "> ",
        "#' @Usage paste_(...)",
        "> ",
        "#'",
        "> ",
        "#' @param ... one or more R objects to convert to characters",
        "> ",
        "#'",
        "> ",
        "#' @return A string ",
        "> ",
        "#' @Details shortcut for paste(\"a\", \"b\", sep =\"_\")",
        "> ",
        "#'  ",
        "> ",
        "#' @author Christopher J. Brown",
        "> ",
        "#' @rdname paste_",
        "> ",
        "#' @export",
        "> ",
        "",
        "> ",
        "paste_ <- function(...){",
        "+ ",
        "  paste(..., sep = \"_\")",
        "+ ",
        "}",
        "> ",
        "dsplots <- dout %>%",
        "+ ",
        "  group_by(ID) %>%",
        "+ ",
        "  with_groups({",
        "+ ",
        "    dsdf <- bind_cols(dat, ",
        "+ ",
        "                      fitted = predict(model[[1]])[,1],",
        "+ ",
        "                      #Note Mean estimate is in col 1 of ",
        "+ ",
        "                      #brms predict",
        "+ ",
        "                      resid = ds_resids(dat$y, ",
        "+ ",
        "                                        predict(model[[1]])[,1], ",
        "+ ",
        "                                        plot = FALSE))",
        "+ ",
        "    g1 <- ggplot(dsdf) + ",
        "+ ",
        "      aes(x = fitted, y = resid, color = x2) + ",
        "+ ",
        "      geom_point()  +",
        "+ ",
        "      ggtitle(paste_(form, family, prior))",
        "+ ",
        "    #save plot to file ",
        "+ ",
        "    # ggsave(g1, file = paste0(\"figures/model-\", ID, \".png\"))",
        "+ ",
        "    list(g1)",
        "+ ",
        "  })",
        "> ",
        "dsplots[[1]]",
        "[[1]]\n\n",
        "> ",
        "dsplots[[3]]",
        "[[1]]\n\n",
        "> ",
        "coef(dout$model[[1]])",
        "Error: No group-level effects detected. Call method 'fixef' to access population-level effects.\n",
        "> ",
        "fixef(dout$model[[1]])",
        "          Estimate  Est.Error     Q2.5    Q97.5\nIntercept 1.933287 0.09760685 1.739894 2.120419\nx1        1.360416 0.14227840 1.083312 1.643743\n",
        "> ",
        "dout$model %>%",
        "+ ",
        "  map(~fixef(.x[[1]]))",
        "Error in map(., ~fixef(.x[[1]])) : could not find function \"map\"\n",
        "> ",
        "library(purrr)",
        "> ",
        "dout$model %>%",
        "+ ",
        "  map(~fixef(.x[[1]]))",
        "Error in UseMethod(\"fixef\") : \n  no applicable method for 'fixef' applied to an object of class \"c('brmsformula', 'bform')\"\n",
        "> ",
        "dout$model",
        "[[1]]\n Family: poisson \n  Links: mu = log \nFormula: y ~ x1 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI\nIntercept     1.93      0.10     1.74\nx1            1.36      0.14     1.08\n          u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     2.12 1.00     1852     2187\nx1            1.64 1.00     2015     2339\n\nSamples were drawn using sampling(NUTS). ",
        "For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n[[2]]\n Family: negbinomial \n  Links: mu = log; shape = identity \nFormula: y ~ x1 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI\nIntercept     1.99      0.20     1.61\nx1       ",
        "     1.28      0.32     0.68\n          u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     2.38 1.00     3392     2652\nx1            1.90 1.00     3416     2536\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI\nshape     3.34      0.84     2.00     5.19\n      Rhat Bulk_ESS Tail_ESS\nshape 1.00     3704     3155\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).",
        "\n\n[[3]]\n Family: poisson \n  Links: mu = log \nFormula: y ~ x2 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI\nIntercept     1.59      0.09     1.40\nx2            2.05      0.13     1.78\n          u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.77 1.00     1824     2252\nx2            2.31 1.00     2061     2415\n\nSamples were drawn using sampling(NUTS). ",
        "For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n[[4]]\n Family: negbinomial \n  Links: mu = log; shape = identity \nFormula: y ~ x2 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI\nIntercept     1.58      0.13     1.33\nx2       ",
        "     2.05      0.21     1.65\n          u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.85 1.00     2696     2599\nx2            2.47 1.00     2973     2698\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI\nshape    11.16      4.27     5.35    22.00\n      Rhat Bulk_ESS Tail_ESS\nshape 1.00     2849     2492\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).",
        "\n\n[[5]]\n Family: poisson \n  Links: mu = log \nFormula: y ~ x1 + x2 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI\nIntercept     1.06      0.11     0.83\nx1            1.07      0.13     0.81\nx2            1.86      0.13     1.60\n          u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.27 1.00     2850     2518\nx1            1.34 1.00     2888",
        "     2732\nx2            2.12 1.00     2940     2760\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n[[6]]\n Family: negbinomial \n  Links: mu = log; shape = identity \nFormula: y ~ x1 + x2 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n",
        "          Estimate Est.Error l-95% CI\nIntercept     1.05      0.13     0.80\nx1            1.08      0.16     0.78\nx2            1.88      0.15     1.57\n          u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.30 1.00     3959     3179\nx1            1.39 1.00     4281     3036\nx2            2.18 1.00     3942     2856\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI\nshape    92.68     68.86    20.55   278.70\n      Rhat Bulk_ESS Tail_ESS\nshape 1.00     3701     2853\n\nSamples were drawn using sampling(NUTS). ",
        "For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n[[7]]\n Family: poisson \n  Links: mu = log \nFormula: y ~ x1 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI\nIntercept     2.00      0.09     1.82\nx1            1.26      0.13",
        "     1.00\n          u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     2.18 1.00     1981     1864\nx1            1.53 1.00     2261     2257\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n[[8]]\n Family: negbinomial \n  Links: mu = log; shape = identity \nFormula: y ~ x1 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\n",
        "Population-Level Effects: \n          Estimate Est.Error l-95% CI\nIntercept     2.19      0.18     1.86\nx1            0.92      0.27     0.39\n          u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     2.56 1.00     3104     2824\nx1            1.43 1.00     3340     2804\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI\nshape     3.24      0.82     1.91     5.13\n      Rhat Bulk_ESS Tail_ESS\nshape 1.00     3236     2647\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).",
        "\n\n[[9]]\n Family: poisson \n  Links: mu = log \nFormula: y ~ x2 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI\nIntercept     1.67      0.09     1.49\nx2            1.91      0.13     1.66\n          u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.84 1.00     1701     1900\nx2            2.16 1.00     1916     2071\n\nSamples were drawn using sampling(NUTS). ",
        "For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n[[10]]\n Family: negbinomial \n  Links: mu = log; shape = identity \nFormula: y ~ x2 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI\nIntercept     1.76      0.13     1.52\nx2       ",
        "     1.72      0.21     1.29\n          u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     2.03 1.00     2550     2327\nx2            2.12 1.00     3018     2562\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI\nshape    10.31      3.90     4.78    19.99\n      Rhat Bulk_ESS Tail_ESS\nshape 1.00     2756     2785\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).",
        "\n\n[[11]]\n Family: poisson \n  Links: mu = log \nFormula: y ~ x1 + x2 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI\nIntercept     1.16      0.11     0.95\nx1            1.02      0.13     0.77\nx2            1.75      0.13     1.49\n          u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.38 1.00     2465     2749\nx1            1.29 1.00     2878",
        "     2894\nx2            2.01 1.00     2845     2682\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n[[12]]\n Family: negbinomial \n  Links: mu = log; shape = identity \nFormula: y ~ x1 + x2 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n",
        "          Estimate Est.Error l-95% CI\nIntercept     1.18      0.12     0.93\nx1            1.00      0.15     0.72\nx2            1.74      0.15     1.45\n          u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     1.42 1.00     2960     2802\nx1            1.29 1.00     3683     2813\nx2            2.02 1.00     3117     2787\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI\nshape    91.84     70.41    19.83   281.02\n      Rhat Bulk_ESS Tail_ESS\nshape 1.00     3444     3045\n\nSamples were drawn using sampling(NUTS). ",
        "For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n",
        "> ",
        "dout$model[[1]]",
        " Family: poisson \n  Links: mu = log \nFormula: y ~ x1 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI\nIntercept     1.93      0.10     1.74\nx1            1.36      0.14     1.08\n          u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     2.12 1.00     1852     2187\nx1            1.64 1.00     2015     2339\n\nSamples were drawn using sampling(NUTS). ",
        "For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n",
        "> ",
        "coef(dout$model[[1]])",
        "Error: No group-level effects detected. Call method 'fixef' to access population-level effects.\n",
        "> ",
        "fixef(dout$model[[1]])",
        "          Estimate  Est.Error     Q2.5\nIntercept 1.933287 0.09760685 1.739894\nx1        1.360416 0.14227840 1.083312\n             Q97.5\nIntercept 2.120419\nx1        1.643743\n",
        "> ",
        "dout$model %>%",
        "+ ",
        "  map(~fixef(.x))",
        "[[1]]\n          Estimate  Est.Error     Q2.5    Q97.5\nIntercept 1.933287 0.09760685 1.739894 2.120419\nx1        1.360416 0.14227840 1.083312 1.643743\n\n[[2]]\n          Estimate Est.Error      Q2.5    Q97.5\nIntercept 1.991849 0.1994655 1.6100955 2.382707\nx1        1.277126 0.3176492 0.6792932 1.904883\n\n[[3]]\n          Estimate  Est.Error     Q2.5    Q97.5\nIntercept 1.585302 0.09253749 1.400102 1.766976\nx2        2.046470 0.13467285 1.775495 2.308843\n\n[[4]]\n          Estimate Est.Error     Q2.5    Q97.5\nIntercept",
        " 1.584062 0.1296156 1.327859 1.847756\nx2        2.052542 0.2117590 1.649715 2.471596\n\n[[5]]\n          Estimate Est.Error      Q2.5    Q97.5\nIntercept 1.061323 0.1124952 0.8341581 1.274926\nx1        1.073350 0.1335637 0.8135182 1.338573\nx2        1.859934 0.1336479 1.5963770 2.116248\n\n[[6]]\n          Estimate Est.Error      Q2.5    Q97.5\nIntercept 1.050828 0.1290845 0.7986241 1.297173\nx1        1.076217 0.1551864 0.7758206 1.387526\nx2        1.877249 0.1528619 1.5743089 2.183021\n\n[[7]]\n          Estimate  Est.Error",
        "     Q2.5    Q97.5\nIntercept 1.996606 0.09229015 1.815932 2.176208\nx1        1.262971 0.13409286 1.002143 1.530983\n\n[[8]]\n           Estimate Est.Error      Q2.5    Q97.5\nIntercept 2.1927406 0.1801668 1.8573568 2.559660\nx1        0.9165196 0.2702516 0.3887117 1.426286\n\n[[9]]\n          Estimate  Est.Error     Q2.5    Q97.5\nIntercept 1.669965 0.08937456 1.487854 1.843154\nx2        1.912002 0.12916299 1.664574 2.164732\n\n[[10]]\n          Estimate Est.Error     Q2.5    Q97.5\nIntercept 1.764487 0.1288747 1.524642",
        " 2.026716\nx2        1.719491 0.2072608 1.288443 2.115197\n\n[[11]]\n          Estimate Est.Error      Q2.5    Q97.5\nIntercept 1.162592 0.1135813 0.9462868 1.384317\nx1        1.024777 0.1293883 0.7702423 1.285565\nx2        1.749545 0.1292815 1.4933265 2.009817\n\n[[12]]\n          Estimate Est.Error      Q2.5    Q97.5\nIntercept 1.178474 0.1247567 0.9333168 1.422599\nx1        1.002923 0.1464391 0.7162240 1.285232\nx2        1.737246 0.1465487 1.4483628 2.022980\n\n",
        "> ",
        "dout$model %>%",
        "+ ",
        "  map(~fixef(.x)) %>%",
        "+ ",
        "  bind_rows",
        "Error: Argument 1 must have names\n",
        "> ",
        "dout$model %>%",
        "+ ",
        "  map(~fixef(.x)) %>%",
        "+ ",
        "  bind_rows()",
        "Error: Argument 1 must have names\n",
        "> ",
        "dout$model %>%",
        "+ ",
        "  map(~fixef(.x)) %>%",
        "+ ",
        "  setNames(dfsim$ID) %>%",
        "+ ",
        "  bind_rows()",
        "Error: Argument 5 must be length 8, not 12\n",
        "> ",
        "dout$model %>%",
        "+ ",
        "  map(~fixef(.x)) %>%",
        "+ ",
        "  setNames(dfsim$ID)",
        "$`1`\n          Estimate  Est.Error     Q2.5    Q97.5\nIntercept 1.933287 0.09760685 1.739894 2.120419\nx1        1.360416 0.14227840 1.083312 1.643743\n\n$`2`\n          Estimate Est.Error      Q2.5    Q97.5\nIntercept 1.991849 0.1994655 1.6100955 2.382707\nx1        1.277126 0.3176492 0.6792932 1.904883\n\n$`3`\n          Estimate  Est.Error     Q2.5    Q97.5\nIntercept 1.585302 0.09253749 1.400102 1.766976\nx2        2.046470 0.13467285 1.775495 2.308843\n\n$`4`\n          Estimate Est.Error     Q2.5    Q97.5\nIntercept 1.584062",
        " 0.1296156 1.327859 1.847756\nx2        2.052542 0.2117590 1.649715 2.471596\n\n$`5`\n          Estimate Est.Error      Q2.5    Q97.5\nIntercept 1.061323 0.1124952 0.8341581 1.274926\nx1        1.073350 0.1335637 0.8135182 1.338573\nx2        1.859934 0.1336479 1.5963770 2.116248\n\n$`6`\n          Estimate Est.Error      Q2.5    Q97.5\nIntercept 1.050828 0.1290845 0.7986241 1.297173\nx1        1.076217 0.1551864 0.7758206 1.387526\nx2        1.877249 0.1528619 1.5743089 2.183021\n\n$`7`\n          Estimate  Est.Error     Q2.5",
        "    Q97.5\nIntercept 1.996606 0.09229015 1.815932 2.176208\nx1        1.262971 0.13409286 1.002143 1.530983\n\n$`8`\n           Estimate Est.Error      Q2.5    Q97.5\nIntercept 2.1927406 0.1801668 1.8573568 2.559660\nx1        0.9165196 0.2702516 0.3887117 1.426286\n\n$`9`\n          Estimate  Est.Error     Q2.5    Q97.5\nIntercept 1.669965 0.08937456 1.487854 1.843154\nx2        1.912002 0.12916299 1.664574 2.164732\n\n$`10`\n          Estimate Est.Error     Q2.5    Q97.5\nIntercept 1.764487 0.1288747 1.524642 2.026716\nx2       ",
        " 1.719491 0.2072608 1.288443 2.115197\n\n$`11`\n          Estimate Est.Error      Q2.5    Q97.5\nIntercept 1.162592 0.1135813 0.9462868 1.384317\nx1        1.024777 0.1293883 0.7702423 1.285565\nx2        1.749545 0.1292815 1.4933265 2.009817\n\n$`12`\n          Estimate Est.Error      Q2.5    Q97.5\nIntercept 1.178474 0.1247567 0.9333168 1.422599\nx1        1.002923 0.1464391 0.7162240 1.285232\nx2        1.737246 0.1465487 1.4483628 2.022980\n\n",
        "> ",
        "?bind_rows",
        "> ",
        "dout$model %>%",
        "+ ",
        "  map(~data.frame(fixef(.x))) %>%",
        "+ ",
        "  setNames(dfsim$ID) %>%",
        "+ ",
        "  bind_rows()",
        "    Estimate  Est.Error      Q2.5    Q97.5\n1  1.9332869 0.09760685 1.7398940 2.120419\n2  1.3604163 0.14227840 1.0833121 1.643743\n3  1.9918493 0.19946552 1.6100955 2.382707\n4  1.2771259 0.31764916 0.6792932 1.904883\n5  1.5853022 0.09253749 1.4001017 1.766976\n6  2.0464702 0.13467285 1.7754947 2.308843\n7  1.5840616 0.12961563 1.3278587 1.847756\n8  2.0525422 0.21175900 1.6497148 2.471596\n9  1.0613231 0.11249516 0.8341581 1.274926\n10 1.0733505 0.13356367 0.8135182 1.338573\n11 1.8599338 0.13364793 1.5963770 2.116248",
        "\n12 1.0508282 0.12908447 0.7986241 1.297173\n13 1.0762166 0.15518638 0.7758206 1.387526\n14 1.8772487 0.15286186 1.5743089 2.183021\n15 1.9966055 0.09229015 1.8159318 2.176208\n16 1.2629714 0.13409286 1.0021435 1.530983\n17 2.1927406 0.18016683 1.8573568 2.559660\n18 0.9165196 0.27025157 0.3887117 1.426286\n19 1.6699654 0.08937456 1.4878535 1.843154\n20 1.9120023 0.12916299 1.6645740 2.164732\n21 1.7644870 0.12887466 1.5246416 2.026716\n22 1.7194912 0.20726084 1.2884430 2.115197\n23 1.1625917 0.11358126 0.9462868 1.384317",
        "\n24 1.0247773 0.12938826 0.7702423 1.285565\n25 1.7495449 0.12928153 1.4933265 2.009817\n26 1.1784740 0.12475669 0.9333168 1.422599\n27 1.0029232 0.14643909 0.7162240 1.285232\n28 1.7372457 0.14654871 1.4483628 2.022980\n",
        "> ",
        "dfcoef <- dout$model %>%",
        "+ ",
        "  map(~data.frame(fixef(.x))) %>%",
        "+ ",
        "  setNames(dfsim$ID) %>%",
        "+ ",
        "  bind_rows()",
        "> ",
        "head(dfcoef)",
        "  Estimate  Est.Error      Q2.5    Q97.5\n1 1.933287 0.09760685 1.7398940 2.120419\n2 1.360416 0.14227840 1.0833121 1.643743\n3 1.991849 0.19946552 1.6100955 2.382707\n4 1.277126 0.31764916 0.6792932 1.904883\n5 1.585302 0.09253749 1.4001017 1.766976\n6 2.046470 0.13467285 1.7754947 2.308843\n",
        "> ",
        "dfcoef <- dout$model %>%",
        "+ ",
        "  map(~data.frame(fixef(.x))) %>%",
        "+ ",
        "  setNames(dfsim$ID) %>%",
        "+ ",
        "  bind_rows(.id = \"ID\")",
        "> ",
        "dfcoef",
        "   ID  Estimate  Est.Error      Q2.5    Q97.5\n1   1 1.9332869 0.09760685 1.7398940 2.120419\n2   1 1.3604163 0.14227840 1.0833121 1.643743\n3   2 1.9918493 0.19946552 1.6100955 2.382707\n4   2 1.2771259 0.31764916 0.6792932 1.904883\n5   3 1.5853022 0.09253749 1.4001017 1.766976\n6   3 2.0464702 0.13467285 1.7754947 2.308843\n7   4 1.5840616 0.12961563 1.3278587 1.847756\n8   4 2.0525422 0.21175900 1.6497148 2.471596\n9   5 1.0613231 0.11249516 0.8341581 1.274926\n10  5 1.0733505 0.13356367 0.8135182 1.338573\n11  5 1.8599338",
        " 0.13364793 1.5963770 2.116248\n12  6 1.0508282 0.12908447 0.7986241 1.297173\n13  6 1.0762166 0.15518638 0.7758206 1.387526\n14  6 1.8772487 0.15286186 1.5743089 2.183021\n15  7 1.9966055 0.09229015 1.8159318 2.176208\n16  7 1.2629714 0.13409286 1.0021435 1.530983\n17  8 2.1927406 0.18016683 1.8573568 2.559660\n18  8 0.9165196 0.27025157 0.3887117 1.426286\n19  9 1.6699654 0.08937456 1.4878535 1.843154\n20  9 1.9120023 0.12916299 1.6645740 2.164732\n21 10 1.7644870 0.12887466 1.5246416 2.026716\n22 10 1.7194912 0.20726084",
        " 1.2884430 2.115197\n23 11 1.1625917 0.11358126 0.9462868 1.384317\n24 11 1.0247773 0.12938826 0.7702423 1.285565\n25 11 1.7495449 0.12928153 1.4933265 2.009817\n26 12 1.1784740 0.12475669 0.9333168 1.422599\n27 12 1.0029232 0.14643909 0.7162240 1.285232\n28 12 1.7372457 0.14654871 1.4483628 2.022980\n",
        "> ",
        "?fixef",
        "> ",
        "dout$model[[1]]",
        " Family: poisson \n  Links: mu = log \nFormula: y ~ x1 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI\nIntercept     1.93      0.10     1.74\nx1            1.36      0.14     1.08\n          u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     2.12 1.00     1852     2187\nx1            1.64 1.00     2015     2339\n\nSamples were drawn using sampling(NUTS). ",
        "For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n",
        "> ",
        "dout$model[[1]]$model",
        "// generated with brms 2.11.1\nfunctions {\n}\ndata {\n  int<lower=1> N;  // number of observations\n  int Y[N];  // response variable\n  int<lower=1> K;  // number of population-level effects\n  matrix[N, K] X;  // population-level design matrix\n  int prior_only;  // should the likelihood be ignored?\n}\ntransformed data {\n  int Kc = K - 1;\n  matrix[N, Kc] Xc;  // centered version of X without an intercept\n  vector[Kc] means_X;  // column means of X before centering\n  for (i in 2:K) {\n    means_X[i - 1] = mean(X[, i]);\n    Xc[, i - 1] = X[, i] - means_X[i - 1];\n  }\n}\nparameters {\n  vector[Kc] b;  // population-level effects\n  // temporary intercept for centered predictors\n  real Intercept;\n}\ntransformed parameters {\n}\nmodel {\n  // priors including all constants\n  target += normal_lpdf(b | 0, 10);\n  target += student_t_lpdf(Intercept | 3, 2, 10);\n  // likelihood including all constants\n  if (!prior_only) {\n    target += poisson_log_glm_lpmf(Y | Xc, Intercept, b);\n  }\n}\ngenerated quantities {\n  // actual population-level intercept\n  real b_Intercept = Intercept - dot_product(means_X, b);\n}\n",
        "> ",
        "dout$model[[1]]$fit",
        "Inference for Stan model: 67f9c30a5b8c6cf31f56f19c8f15bc6f.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n               mean se_mean   sd    2.5%\nb_Intercept    1.93    0.00 0.10    1.74\nb_x1           1.36    0.00 0.14    1.08\nIntercept      2.67    0.00 0.04    2.59\nlp__        -249.78    0.02 1.04 -252.58\n                25%     50%     75%   97.5%\nb_Intercept    1.87    1.93    2.00    2.12\nb_x1           1.27    1.36    1.46    1.64",
        "\nIntercept      2.64    2.67    2.70    2.74\nlp__        -250.15 -249.47 -249.05 -248.78\n            n_eff Rhat\nb_Intercept  1843    1\nb_x1         2003    1\nIntercept    2473    1\nlp__         1882    1\n\nSamples were drawn using NUTS(diag_e) at Sun Feb 16 13:36:03 2020.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n",
        "> ",
        "dout$model[[1]]$fit$b_Intercept",
        "Error in dout$model[[1]]$fit$b_Intercept : \n  $ operator not defined for this S4 class\n",
        "> ",
        "dout$model[[1]]$fit",
        "Inference for Stan model: 67f9c30a5b8c6cf31f56f19c8f15bc6f.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n               mean se_mean   sd    2.5%\nb_Intercept    1.93    0.00 0.10    1.74\nb_x1           1.36    0.00 0.14    1.08\nIntercept      2.67    0.00 0.04    2.59\nlp__        -249.78    0.02 1.04 -252.58\n                25%     50%     75%   97.5%\nb_Intercept    1.87    1.93    2.00    2.12\nb_x1           1.27    1.36    1.46    1.64",
        "\nIntercept      2.64    2.67    2.70    2.74\nlp__        -250.15 -249.47 -249.05 -248.78\n            n_eff Rhat\nb_Intercept  1843    1\nb_x1         2003    1\nIntercept    2473    1\nlp__         1882    1\n\nSamples were drawn using NUTS(diag_e) at Sun Feb 16 13:36:03 2020.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n",
        "> ",
        "str(dout$model[[1]]$fit)",
        "Formal class 'stanfit' [package \"rstan\"] with 10 slots\n  ..@ model_name: chr \"67f9c30a5b8c6cf31f56f19c8f15bc6f\"\n  ..@ model_pars: chr [1:4] \"b\" \"Intercept\" \"b_Intercept\" \"lp__\"\n  ..@ par_dims  :List of 4\n  .. ..$ b          : num 1\n  .. ..$ Intercept  : num(0) \n  .. ..$ b_Intercept: num(0) \n  .. ..$ lp__       : num(0) \n  ..@ mode      : int 0\n  ..@ sim       :List of 15\n  .. ..$ samples      :List of 4\n  .. .. ..$ :List of 4\n  .. .. .. ..$ b_Intercept: num [1:2000] 0.2 0.2 0.2 0.2 0.298 ...\n  .. .. .. ..$ ",
        "b_x1       : num [1:2000] -0.193 -0.193 -0.193 -0.193 -0.159 ...\n  .. .. .. ..$ Intercept  : num [1:2000] 0.0956 0.0956 0.0956 0.0956 0.2124 ...\n  .. .. .. ..$ lp__       : num [1:2000] -1645 -1645 -1645 -1645 -1558 ...\n  .. .. .. ..- attr(*, \"test_grad\")= logi FALSE\n  .. .. .. ..- attr(*, \"args\")=List of 16\n  .. .. .. .. ..$ append_samples    : logi FALSE\n  .. .. .. .. ..$ chain_id          : num 1\n  .. .. .. .. ..$ control           :List of 12\n  .. .. .. .. .. ..$ adapt_delta      : num 0.8\n  .. .. .. .. .. ..",
        "$ adapt_engaged    : logi TRUE\n  .. .. .. .. .. ..$ adapt_gamma      : num 0.05\n  .. .. .. .. .. ..$ adapt_init_buffer: num 75\n  .. .. .. .. .. ..$ adapt_kappa      : num 0.75\n  .. .. .. .. .. ..$ adapt_t0         : num 10\n  .. .. .. .. .. ..$ adapt_term_buffer: num 50\n  .. .. .. .. .. ..$ adapt_window     : num 25\n  .. .. .. .. .. ..$ max_treedepth    : int 10\n  .. .. .. .. .. ..$ metric           : chr \"diag_e\"\n  .. .. .. .. .. ..$ stepsize         : num 1\n  .. .. .. .. .. ..$ stepsize_jitter  : num 0\n  .. .. .. .. ..",
        "$ enable_random_init: logi TRUE\n  .. .. .. .. ..$ init              : chr \"random\"\n  .. .. .. .. ..$ init_list         : NULL\n  .. .. .. .. ..$ init_radius       : num 2\n  .. .. .. .. ..$ iter              : int 2000\n  .. .. .. .. ..$ method            : chr \"sampling\"\n  .. .. .. .. ..$ random_seed       : chr \"1391338540\"\n  .. .. .. .. ..$ refresh           : int 200\n  .. .. .. .. ..$ sampler_t         : chr \"NUTS(diag_e)\"\n  .. .. .. .. ..$ save_warmup       : logi TRUE\n  .. .. .. .. ..$ test_grad         ",
        ": logi FALSE\n  .. .. .. .. ..$ thin              : int 1\n  .. .. .. .. ..$ warmup            : int 1000\n  .. .. .. ..- attr(*, \"inits\")= num [1:3] -0.314 -1.364 -1.194\n  .. .. .. ..- attr(*, \"mean_pars\")= num [1:3] 1.36 2.67 1.93\n  .. .. .. ..- attr(*, \"mean_lp__\")= num -250\n  .. .. .. ..- attr(*, \"adaptation_info\")= chr \"# Adaptation terminated\\n# Step size = 0.793007\\n# Diagonal elements of inverse mass matrix:\\n# 0.0206844, 0.00163328\\n\"\n  .. .. .. ..- attr(*, \"elapsed_time\")= Named num [1:2] 0.056 0.054",
        "\n  .. .. .. .. ..- attr(*, \"names\")= chr [1:2] \"warmup\" \"sample\"\n  .. .. .. ..- attr(*, \"sampler_params\")=List of 6\n  .. .. .. .. ..$ accept_stat__: num [1:2000] 1 0 0 0 1 ...\n  .. .. .. .. ..$ stepsize__   : num [1:2000] 0.0625 14.3855 2.4312 0.2398 0.0186 ...\n  .. .. .. .. ..$ treedepth__  : num [1:2000] 1 0 0 0 1 1 1 1 2 1 ...\n  .. .. .. .. ..$ n_leapfrog__ : num [1:2000] 1 1 1 1 1 1 3 1 3 1 ...\n  .. .. .. .. ..$ divergent__  : num [1:2000] 0 1 1 1 0 0 1 0 0 0 ...\n  .. .. .. .. ..$ energy__     : num [1:2000] ",
        "2705 1646 1646 1645 1645 ...\n  .. .. .. ..- attr(*, \"return_code\")= int 0\n  .. .. ..$ :List of 4\n  .. .. .. ..$ b_Intercept: num [1:2000] -0.0533 -0.0533 -0.0533 -0.0533 0.0682 ...\n  .. .. .. ..$ b_x1       : num [1:2000] 0.539 0.539 0.539 0.539 0.526 ...\n  .. .. .. ..$ Intercept  : num [1:2000] 0.238 0.238 0.238 0.238 0.353 ...\n  .. .. .. ..$ lp__       : num [1:2000] -1487 -1487 -1487 -1487 -1407 ...\n  .. .. .. ..- attr(*, \"test_grad\")= logi FALSE\n  .. .. .. ..- attr(*, \"args\")=List of 16\n  .. .. .. .. ..",
        "$ append_samples    : logi FALSE\n  .. .. .. .. ..$ chain_id          : num 2\n  .. .. .. .. ..$ control           :List of 12\n  .. .. .. .. .. ..$ adapt_delta      : num 0.8\n  .. .. .. .. .. ..$ adapt_engaged    : logi TRUE\n  .. .. .. .. .. ..$ adapt_gamma      : num 0.05\n  .. .. .. .. .. ..$ adapt_init_buffer: num 75\n  .. .. .. .. .. ..$ adapt_kappa      : num 0.75\n  .. .. .. .. .. ..$ adapt_t0         : num 10\n  .. .. .. .. .. ..$ adapt_term_buffer: num 50\n  .. .. .. .. .. ..$ adapt_window     : num 25\n  .. .. .. .. .. ..",
        "$ max_treedepth    : int 10\n  .. .. .. .. .. ..$ metric           : chr \"diag_e\"\n  .. .. .. .. .. ..$ stepsize         : num 1\n  .. .. .. .. .. ..$ stepsize_jitter  : num 0\n  .. .. .. .. ..$ enable_random_init: logi TRUE\n  .. .. .. .. ..$ init              : chr \"random\"\n  .. .. .. .. ..$ init_list         : NULL\n  .. .. .. .. ..$ init_radius       : num 2\n  .. .. .. .. ..$ iter              : int 2000\n  .. .. .. .. ..$ method            : chr \"sampling\"\n  .. .. .. .. ..$ random_seed       : chr \"1391338540\"",
        "\n  .. .. .. .. ..$ refresh           : int 200\n  .. .. .. .. ..$ sampler_t         : chr \"NUTS(diag_e)\"\n  .. .. .. .. ..$ save_warmup       : logi TRUE\n  .. .. .. .. ..$ test_grad         : logi FALSE\n  .. .. .. .. ..$ thin              : int 1\n  .. .. .. .. ..$ warmup            : int 1000\n  .. .. .. ..- attr(*, \"inits\")= num [1:3] 0.401 -1.239 -1.455\n  .. .. .. ..- attr(*, \"mean_pars\")= num [1:3] 1.36 2.67 1.93\n  .. .. .. ..- attr(*, \"mean_lp__\")= num -250\n  .. .. .. ..- attr(*, \"adaptation_info\")= chr \"# Adaptation terminated\\n# Step size = 0.786886\\n# Diagonal elements of inverse mass matrix:\\n# 0.0176959, 0.00148968\\n\"",
        "\n  .. .. .. ..- attr(*, \"elapsed_time\")= Named num [1:2] 0.069 0.069\n  .. .. .. .. ..- attr(*, \"names\")= chr [1:2] \"warmup\" \"sample\"\n  .. .. .. ..- attr(*, \"sampler_params\")=List of 6\n  .. .. .. .. ..$ accept_stat__: num [1:2000] 1 0 0 0 1 ...\n  .. .. .. .. ..$ stepsize__   : num [1:2000] 0.0625 14.3855 2.4312 0.2398 0.0186 ...\n  .. .. .. .. ..$ treedepth__  : num [1:2000] 1 0 0 0 1 2 2 1 1 4 ...\n  .. .. .. .. ..$ n_leapfrog__ : num [1:2000] 1 1 1 1 1 3 3 1 3 15 ...\n  .. .. .. .. ..$ divergent__  : num [1:2000] ",
        "0 1 1 1 0 0 0 0 1 0 ...\n  .. .. .. .. ..$ energy__     : num [1:2000] 2548 1488 1489 1487 1487 ...\n  .. .. .. ..- attr(*, \"return_code\")= int 0\n  .. .. ..$ :List of 4\n  .. .. .. ..$ b_Intercept: num [1:2000] 1.79 1.79 1.79 1.79 1.79 ...\n  .. .. .. ..$ b_x1       : num [1:2000] 1.76 1.76 1.76 1.76 1.77 ...\n  .. .. .. ..$ Intercept  : num [1:2000] 2.75 2.75 2.75 2.75 2.74 ...\n  .. .. .. ..$ lp__       : num [1:2000] -259 -259 -259 -259 -259 ...\n  .. .. .. ..- attr(*, \"test_grad\")= logi FALSE\n  .. .. .. ..- attr(*, \"args\")=",
        "List of 16\n  .. .. .. .. ..$ append_samples    : logi FALSE\n  .. .. .. .. ..$ chain_id          : num 3\n  .. .. .. .. ..$ control           :List of 12\n  .. .. .. .. .. ..$ adapt_delta      : num 0.8\n  .. .. .. .. .. ..$ adapt_engaged    : logi TRUE\n  .. .. .. .. .. ..$ adapt_gamma      : num 0.05\n  .. .. .. .. .. ..$ adapt_init_buffer: num 75\n  .. .. .. .. .. ..$ adapt_kappa      : num 0.75\n  .. .. .. .. .. ..$ adapt_t0         : num 10\n  .. .. .. .. .. ..$ adapt_term_buffer: num 50\n  .. .. .. .. .. ..$ adapt_window     ",
        ": num 25\n  .. .. .. .. .. ..$ max_treedepth    : int 10\n  .. .. .. .. .. ..$ metric           : chr \"diag_e\"\n  .. .. .. .. .. ..$ stepsize         : num 1\n  .. .. .. .. .. ..$ stepsize_jitter  : num 0\n  .. .. .. .. ..$ enable_random_init: logi TRUE\n  .. .. .. .. ..$ init              : chr \"random\"\n  .. .. .. .. ..$ init_list         : NULL\n  .. .. .. .. ..$ init_radius       : num 2\n  .. .. .. .. ..$ iter              : int 2000\n  .. .. .. .. ..$ method            : chr \"sampling\"\n  .. .. .. .. ..$ random_seed       ",
        ": chr \"1391338540\"\n  .. .. .. .. ..$ refresh           : int 200\n  .. .. .. .. ..$ sampler_t         : chr \"NUTS(diag_e)\"\n  .. .. .. .. ..$ save_warmup       : logi TRUE\n  .. .. .. .. ..$ test_grad         : logi FALSE\n  .. .. .. .. ..$ thin              : int 1\n  .. .. .. .. ..$ warmup            : int 1000\n  .. .. .. ..- attr(*, \"inits\")= num [1:3] 1.652 1.621 0.727\n  .. .. .. ..- attr(*, \"mean_pars\")= num [1:3] 1.36 2.67 1.93\n  .. .. .. ..- attr(*, \"mean_lp__\")= num -250\n  .. .. .. ..- attr(*, \"adaptation_info\")=",
        " chr \"# Adaptation terminated\\n# Step size = 0.841067\\n# Diagonal elements of inverse mass matrix:\\n# 0.0196728, 0.00149035\\n\"\n  .. .. .. ..- attr(*, \"elapsed_time\")= Named num [1:2] 0.116 0.049\n  .. .. .. .. ..- attr(*, \"names\")= chr [1:2] \"warmup\" \"sample\"\n  .. .. .. ..- attr(*, \"sampler_params\")=List of 6\n  .. .. .. .. ..$ accept_stat__: num [1:2000] 6.67e-01 0.00 0.00 5.47e-39 9.99e-01 ...\n  .. .. .. .. ..$ stepsize__   : num [1:2000] 0.0625 7.84723 1.10816 0.09865 0.00719 ...\n  .. .. .. .. ..$ treedepth__  ",
        ": num [1:2000] 1 0 0 1 2 3 5 2 1 2 ...\n  .. .. .. .. ..$ n_leapfrog__ : num [1:2000] 3 1 1 1 3 7 31 3 1 3 ...\n  .. .. .. .. ..$ divergent__  : num [1:2000] 1 1 1 0 0 0 0 0 0 0 ...\n  .. .. .. .. ..$ energy__     : num [1:2000] 370 259 259 259 259 ...\n  .. .. .. ..- attr(*, \"return_code\")= int 0\n  .. .. ..$ :List of 4\n  .. .. .. ..$ b_Intercept: num [1:2000] 1.45 1.45 1.45 1.45 1.75 ...\n  .. .. .. ..$ b_x1       : num [1:2000] 1.72 1.72 1.72 1.72 1.59 ...\n  .. .. .. ..$ Intercept  : num [1:2000] 2.38 2.38 2.38 2.38 2.61",
        " ...\n  .. .. .. ..$ lp__       : num [1:2000] -275 -275 -275 -275 -251 ...\n  .. .. .. ..- attr(*, \"test_grad\")= logi FALSE\n  .. .. .. ..- attr(*, \"args\")=List of 16\n  .. .. .. .. ..$ append_samples    : logi FALSE\n  .. .. .. .. ..$ chain_id          : num 4\n  .. .. .. .. ..$ control           :List of 12\n  .. .. .. .. .. ..$ adapt_delta      : num 0.8\n  .. .. .. .. .. ..$ adapt_engaged    : logi TRUE\n  .. .. .. .. .. ..$ adapt_gamma      : num 0.05\n  .. .. .. .. .. ..$ adapt_init_buffer: num 75\n  .. .. .. .. .. ..",
        "$ adapt_kappa      : num 0.75\n  .. .. .. .. .. ..$ adapt_t0         : num 10\n  .. .. .. .. .. ..$ adapt_term_buffer: num 50\n  .. .. .. .. .. ..$ adapt_window     : num 25\n  .. .. .. .. .. ..$ max_treedepth    : int 10\n  .. .. .. .. .. ..$ metric           : chr \"diag_e\"\n  .. .. .. .. .. ..$ stepsize         : num 1\n  .. .. .. .. .. ..$ stepsize_jitter  : num 0\n  .. .. .. .. ..$ enable_random_init: logi TRUE\n  .. .. .. .. ..$ init              : chr \"random\"\n  .. .. .. .. ..$ init_list         : NULL\n  .. .. .. .. ..",
        "$ init_radius       : num 2\n  .. .. .. .. ..$ iter              : int 2000\n  .. .. .. .. ..$ method            : chr \"sampling\"\n  .. .. .. .. ..$ random_seed       : chr \"1391338540\"\n  .. .. .. .. ..$ refresh           : int 200\n  .. .. .. .. ..$ sampler_t         : chr \"NUTS(diag_e)\"\n  .. .. .. .. ..$ save_warmup       : logi TRUE\n  .. .. .. .. ..$ test_grad         : logi FALSE\n  .. .. .. .. ..$ thin              : int 1\n  .. .. .. .. ..$ warmup            : int 1000\n  .. .. .. ..- attr(*, \"inits\")= num [1:3] ",
        "1.636 1.49 0.605\n  .. .. .. ..- attr(*, \"mean_pars\")= num [1:3] 1.36 2.67 1.93\n  .. .. .. ..- attr(*, \"mean_lp__\")= num -250\n  .. .. .. ..- attr(*, \"adaptation_info\")= chr \"# Adaptation terminated\\n# Step size = 0.685793\\n# Diagonal elements of inverse mass matrix:\\n# 0.0171306, 0.00136862\\n\"\n  .. .. .. ..- attr(*, \"elapsed_time\")= Named num [1:2] 0.056 0.065\n  .. .. .. .. ..- attr(*, \"names\")= chr [1:2] \"warmup\" \"sample\"\n  .. .. .. ..- attr(*, \"sampler_params\")=List of 6\n  .. .. .. .. ..$ accept_stat__: num [1:2000] ",
        "1 0 0 0 1 ...\n  .. .. .. .. ..$ stepsize__   : num [1:2000] 0.0625 14.3855 2.4312 0.2398 0.0186 ...\n  .. .. .. .. ..$ treedepth__  : num [1:2000] 1 0 0 0 3 3 3 2 2 1 ...\n  .. .. .. .. ..$ n_leapfrog__ : num [1:2000] 1 1 1 1 7 7 15 7 7 3 ...\n  .. .. .. .. ..$ divergent__  : num [1:2000] 0 1 1 1 0 0 0 0 0 0 ...\n  .. .. .. .. ..$ energy__     : num [1:2000] 468 275 276 275 276 ...\n  .. .. .. ..- attr(*, \"return_code\")= int 0\n  .. ..$ iter         : num 2000\n  .. ..$ thin         : num 1\n  .. ..$ warmup       :",
        " num 1000\n  .. ..$ chains       : num 4\n  .. ..$ n_save       : num [1:4] 2000 2000 2000 2000\n  .. ..$ warmup2      : num [1:4] 1000 1000 1000 1000\n  .. ..$ permutation  :List of 4\n  .. .. ..$ : int [1:1000] 276 315 924 246 10 743 5 201 78 513 ...\n  .. .. ..$ : int [1:1000] 529 317 964 919 335 689 233 706 682 204 ...\n  .. .. ..$ : int [1:1000] 660 200 219 320 919 905 207 243 147 916 ...\n  .. .. ..$ : int [1:1000] 536 436 10 381 253 886 228 446 142 907 ...\n  .. ..$ pars_oi      : chr [1:4] \"b_Intercept\" \"b\" \"Intercept\" \"lp__\"",
        "\n  .. ..$ dims_oi      :List of 4\n  .. .. ..$ b_Intercept: num(0) \n  .. .. ..$ b          : num 1\n  .. .. ..$ Intercept  : num(0) \n  .. .. ..$ lp__       : num(0) \n  .. ..$ fnames_oi    : chr [1:4] \"b_Intercept\" \"b_x1\" \"Intercept\" \"lp__\"\n  .. ..$ n_flatnames  : int 4\n  .. ..$ pars_oi_old  : chr [1:4] \"b\" \"Intercept\" \"b_Intercept\" \"lp__\"\n  .. ..$ dims_oi_old  :List of 4\n  .. .. ..$ b          : num 1\n  .. .. ..$ Intercept  : num(0) \n  .. .. ..$ b_Intercept: num(0) \n  .. .. ..$ lp__       : num(0) \n  .. ..$ fnames_oi_old",
        ": chr [1:4] \"b[1]\" \"Intercept\" \"b_Intercept\" \"lp__\"\n  ..@ inits     :List of 4\n  .. ..$ :List of 3\n  .. .. ..$ b          : num [1(1d)] -0.314\n  .. .. ..$ Intercept  : num -1.36\n  .. .. ..$ b_Intercept: num -1.19\n  .. ..$ :List of 3\n  .. .. ..$ b          : num [1(1d)] 0.401\n  .. .. ..$ Intercept  : num -1.24\n  .. .. ..$ b_Intercept: num -1.46\n  .. ..$ :List of 3\n  .. .. ..$ b          : num [1(1d)] 1.65\n  .. .. ..$ Intercept  : num 1.62\n  .. .. ..$ b_Intercept: num 0.727\n  .. ..$ :List of 3\n  .. .. ..$ b          ",
        ": num [1(1d)] 1.64\n  .. .. ..$ Intercept  : num 1.49\n  .. .. ..$ b_Intercept: num 0.605\n  ..@ stan_args :List of 4\n  .. ..$ :List of 8\n  .. .. ..$ chain_id : int 1\n  .. .. ..$ iter     : int 2000\n  .. .. ..$ thin     : int 1\n  .. .. ..$ seed     : int 1391338540\n  .. .. ..$ warmup   : num 1000\n  .. .. ..$ init     : chr \"random\"\n  .. .. ..$ algorithm: chr \"NUTS\"\n  .. .. ..$ method   : chr \"sampling\"\n  .. ..$ :List of 8\n  .. .. ..$ chain_id : int 2\n  .. .. ..$ iter     : int 2000\n  .. .. ..$ thin     : int 1",
        "\n  .. .. ..$ seed     : int 1391338540\n  .. .. ..$ warmup   : num 1000\n  .. .. ..$ init     : chr \"random\"\n  .. .. ..$ algorithm: chr \"NUTS\"\n  .. .. ..$ method   : chr \"sampling\"\n  .. ..$ :List of 8\n  .. .. ..$ chain_id : int 3\n  .. .. ..$ iter     : int 2000\n  .. .. ..$ thin     : int 1\n  .. .. ..$ seed     : int 1391338540\n  .. .. ..$ warmup   : num 1000\n  .. .. ..$ init     : chr \"random\"\n  .. .. ..$ algorithm: chr \"NUTS\"\n  .. .. ..$ method   : chr \"sampling\"\n  .. ..$ :List of 8\n  .. .. ..$ chain_id : int ",
        "4\n  .. .. ..$ iter     : int 2000\n  .. .. ..$ thin     : int 1\n  .. .. ..$ seed     : int 1391338540\n  .. .. ..$ warmup   : num 1000\n  .. .. ..$ init     : chr \"random\"\n  .. .. ..$ algorithm: chr \"NUTS\"\n  .. .. ..$ method   : chr \"sampling\"\n  ..@ stanmodel :Formal class 'stanmodel' [package \"rstan\"] with 5 slots\n  .. .. ..@ model_name  : chr \"67f9c30a5b8c6cf31f56f19c8f15bc6f\"\n  .. .. ..@ model_code  : chr \"// generated with brms 2.11.1\\nfunctions {\\n}\\ndata {\\n  int<lower=1> N;  // number of observations\\n  int Y[N]\"| __truncated__",
        "\n  .. .. .. ..- attr(*, \"model_name2\")= chr \"67f9c30a5b8c6cf31f56f19c8f15bc6f\"\n  .. .. ..@ model_cpp   :List of 2\n  .. .. .. ..$ model_cppname: chr \"model126cf0c2182_67f9c30a5b8c6cf31f56f19c8f15bc6f\"\n  .. .. .. ..$ model_cppcode: chr \"// Code generated by Stan version 2.19.1\\n\\n#include <stan/model/model_header.hpp>\\n\\nnamespace model126cf0c218\"| __truncated__\n  .. .. ..@ mk_cppmodule:function (object)  \n  .. .. ..@ dso         :Formal class 'cxxdso' [package \"rstan\"] with 7 slots\n  .. .. .. .. ..@ sig         ",
        ":List of 1\n  .. .. .. .. .. ..$ file126c47925f89: chr(0) \n  .. .. .. .. ..@ dso_saved   : logi TRUE\n  .. .. .. .. ..@ dso_filename: chr \"file126c47925f89\"\n  .. .. .. .. ..@ modulename  : chr \"stan_fit4model126cf0c2182_67f9c30a5b8c6cf31f56f19c8f15bc6f_mod\"\n  .. .. .. .. ..@ system      : chr \"x86_64, mingw32\"\n  .. .. .. .. ..@ cxxflags    : chr \"CXXFLAGS=-O3 -Wno-unused-variable -Wno-unused-function\"\n  .. .. .. .. ..@ .CXXDSOMISC :<environment: 0x0000000025176a20> \n  ..@ date      : chr \"Sun Feb 16 13:36:03 2020\"",
        "\n  ..@ .MISC     :<environment: 0x000000003348d090> \n",
        "> ",
        "str(dout$model[[1]]$fit,1)",
        "Formal class 'stanfit' [package \"rstan\"] with 10 slots\n",
        "> ",
        "dfcoef <- dout$model %>%",
        "+ ",
        "  map(~loo(.x)) %>%",
        "+ ",
        "  setNames(dfsim$ID) %>%",
        "+ ",
        "  bind_rows(.id = \"ID\")",
        "Error: Argument 1 must be a data frame or a named atomic vector, not a psis_loo/importance_sampling_loo/loo\n",
        "> ",
        "loo(dout$model[[1]])",
        "\nComputed from 4000 by 50 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -250.0 23.8\np_loo        12.6  3.0\nlooic       500.0 47.7\n------\nMonte Carlo SE of elpd_loo is 0.1.\n\nPareto k diagnostic values:\n                         Count Pct.   \n(-Inf, 0.5]   (good)     48    96.0%  \n (0.5, 0.7]   (ok)        2     4.0%  \n   (0.7, 1]   (bad)       0     0.0%  \n   (1, Inf)   (very bad)  0     0.0%  \n            Min. n_eff\n(-Inf, 0.5] 502       \n (0.5, 0.7] 109       \n   (0.7, 1] <NA>      \n   (1, Inf) <NA>      ",
        "\n\nAll Pareto k estimates are ok (k < 0.7).\nSee help('pareto-k-diagnostic') for details.\n",
        "> ",
        "dfcoef <- dout$model %>%",
        "+ ",
        "  map(~loo(.x[[1]])) %>%",
        "+ ",
        "  setNames(dfsim$ID) %>%",
        "+ ",
        "  bind_rows(.id = \"ID\")",
        "Error in UseMethod(\"loo\") : \n  no applicable method for 'loo' applied to an object of class \"c('brmsformula', 'bform')\"\n",
        "> ",
        "dfcoef <- dout$model %>%",
        "+ ",
        "  map(~loo(.x)) %>%",
        "+ ",
        "  setNames(dfsim$ID) %>%",
        "+ ",
        "  bind_rows(.id = \"ID\")",
        "Error: Argument 1 must be a data frame or a named atomic vector, not a psis_loo/importance_sampling_loo/loo\n",
        "> ",
        "dfloo <- dout$model %>%",
        "+ ",
        "  map(~loo(.x)) ",
        "> ",
        "dfloo",
        "[[1]]\n\nComputed from 4000 by 50 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -250.0 23.8\np_loo        12.6  3.0\nlooic       500.0 47.7\n------\nMonte Carlo SE of elpd_loo is 0.1.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     48    96.0%   502       \n (0.5, 0.7]   (ok)        2     4.0%   109       \n   (0.7, 1]   (bad)       0     0.0%   <NA>      \n   (1, Inf)   (very bad)  0     0.0%   <NA>      \n\nAll Pareto k estimates are ok (k < 0.7).\nSee help('pareto-k-diagnostic') for details.\n",
        "\n[[2]]\n\nComputed from 4000 by 50 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -177.1  5.2\np_loo         2.8  0.5\nlooic       354.2 10.3\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n\n[[3]]\n\nComputed from 4000 by 50 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -172.6 13.7\np_loo         6.1  1.6\nlooic       345.3 27.4\n------\nMonte Carlo SE of elpd_loo is 0.1.\n\nAll Pareto k estimates are good (k < 0.5).\n",
        "See help('pareto-k-diagnostic') for details.\n\n[[4]]\n\nComputed from 4000 by 50 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -156.8  6.5\np_loo         3.0  0.8\nlooic       313.5 12.9\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n\n[[5]]\n\nComputed from 4000 by 50 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -137.7  6.6\np_loo         3.5  0.8\nlooic       275.3 13.2\n------\nMonte Carlo SE of elpd_loo is 0.0.\n",
        "\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n\n[[6]]\n\nComputed from 4000 by 50 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -138.5  5.9\np_loo         3.2  0.8\nlooic       277.0 11.8\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n\n[[7]]\n\nComputed from 4000 by 50 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -249.6 23.9\np_loo        11.8  2.8\nlooic       499.2 47.9",
        "\n------\nMonte Carlo SE of elpd_loo is 0.1.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n\n[[8]]\n\nComputed from 4000 by 50 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -177.4  5.4\np_loo         2.5  0.4\nlooic       354.9 10.8\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n\n[[9]]\n\nComputed from 4000 by 50 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -173.1 13.0",
        "\np_loo         6.0  1.5\nlooic       346.2 25.9\n------\nMonte Carlo SE of elpd_loo is 0.1.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n\n[[10]]\n\nComputed from 4000 by 50 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -157.8  6.0\np_loo         2.9  0.6\nlooic       315.7 11.9\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n\n[[11]]\n\nComputed from 4000 by 50 log-likelihood matrix\n",
        "\n         Estimate   SE\nelpd_loo   -138.0  6.3\np_loo         3.3  0.7\nlooic       276.1 12.5\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n\n[[12]]\n\nComputed from 4000 by 50 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -138.9  5.6\np_loo         2.9  0.7\nlooic       277.8 11.2\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n\n",
        "> ",
        "dfloo[[1]]$estimates",
        "           Estimate        SE\nelpd_loo -250.00958 23.827457\np_loo      12.64425  2.991601\nlooic     500.01917 47.654913\n",
        "> ",
        "?loo",
        "> ",
        "?loo",
        "> ",
        "dfloo <- dout$model %>%",
        "+ ",
        "  map(~loo(.x)$estimates[3,]) %>%",
        "+ ",
        "  setNames(dfsim$ID) %>%",
        "+ ",
        "  bind_rows(.id = \"ID\")",
        "> ",
        "dfloo",
        "[90m# A tibble: 2 x 13[39m\n  ID      `1`   `2`   `3`   `4`   `5`   `6`   `7`\n  [3m[90m<chr>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m\n[90m1[39m 1     500.  354.  345.  314.  275.  277.  499. \n[90m2[39m 1      47.7  10.3  27.4  12.9  13.2  11.8  47.9\n[90m# ... with 5 more variables: `8` [3m[90m<dbl>[90m[23m, `9` [3m[90m<dbl>[90m[23m,\n#   `10` [3m[90m<dbl>[90m[23m, `11` [3m[90m<dbl>[90m[23m, `12` [3m[90m<dbl>[90m[23m[39m\n",
        "> ",
        "dfloo <- dout$model %>%",
        "+ ",
        "  map(~loo(.x)$estimates[3,])",
        "> ",
        "dfloo",
        "[[1]]\n Estimate        SE \n500.01917  47.65491 \n\n[[2]]\n Estimate        SE \n354.15163  10.33634 \n\n[[3]]\n Estimate        SE \n345.27274  27.38355 \n\n[[4]]\n Estimate        SE \n313.54675  12.92343 \n\n[[5]]\n Estimate        SE \n275.30720  13.17362 \n\n[[6]]\n Estimate        SE \n276.97986  11.81379 \n\n[[7]]\n Estimate        SE \n499.22377  47.85191 \n\n[[8]]\n Estimate        SE \n354.86079  10.79267 \n\n[[9]]\n Estimate        SE \n346.21457  25.94232 \n\n[[10]]\n Estimate        SE \n315.67658  11.91492 \n\n[[11]]\n Estimate        SE ",
        "\n276.05242  12.51905 \n\n[[12]]\n Estimate        SE \n277.75786  11.16051 \n\n",
        "> ",
        "setNames(dfloo, dfsim$ID)",
        "$`1`\n Estimate        SE \n500.01917  47.65491 \n\n$`2`\n Estimate        SE \n354.15163  10.33634 \n\n$`3`\n Estimate        SE \n345.27274  27.38355 \n\n$`4`\n Estimate        SE \n313.54675  12.92343 \n\n$`5`\n Estimate        SE \n275.30720  13.17362 \n\n$`6`\n Estimate        SE \n276.97986  11.81379 \n\n$`7`\n Estimate        SE \n499.22377  47.85191 \n\n$`8`\n Estimate        SE \n354.86079  10.79267 \n\n$`9`\n Estimate        SE \n346.21457  25.94232 \n\n$`10`\n Estimate        SE \n315.67658  11.91492 \n\n$`11`\n Estimate        SE \n276.05242 ",
        " 12.51905 \n\n$`12`\n Estimate        SE \n277.75786  11.16051 \n\n",
        "> ",
        "setNames(dfloo, dfsim$ID) %>% bind_rows()",
        "[90m# A tibble: 2 x 12[39m\n    `1`   `2`   `3`   `4`   `5`   `6`   `7`   `8`\n  [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m\n[90m1[39m 500.  354.  345.  314.  275.  277.  499.  355. \n[90m2[39m  47.7  10.3  27.4  12.9  13.2  11.8  47.9  10.8\n[90m# ... with 4 more variables: `9` [3m[90m<dbl>[90m[23m, `10` [3m[90m<dbl>[90m[23m,\n#   `11` [3m[90m<dbl>[90m[23m, `12` [3m[90m<dbl>[90m[23m[39m\n",
        "> ",
        "setNames(dfloo, dfsim$ID) %>% bind_cols()",
        "[90m# A tibble: 2 x 12[39m\n    `1`   `2`   `3`   `4`   `5`   `6`   `7`   `8`\n  [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m\n[90m1[39m 500.  354.  345.  314.  275.  277.  499.  355. \n[90m2[39m  47.7  10.3  27.4  12.9  13.2  11.8  47.9  10.8\n[90m# ... with 4 more variables: `9` [3m[90m<dbl>[90m[23m, `10` [3m[90m<dbl>[90m[23m,\n#   `11` [3m[90m<dbl>[90m[23m, `12` [3m[90m<dbl>[90m[23m[39m\n",
        "> ",
        "setNames(dfloo, dfsim$ID) %>% bind_rows()",
        "[90m# A tibble: 2 x 12[39m\n    `1`   `2`   `3`   `4`   `5`   `6`   `7`   `8`\n  [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m\n[90m1[39m 500.  354.  345.  314.  275.  277.  499.  355. \n[90m2[39m  47.7  10.3  27.4  12.9  13.2  11.8  47.9  10.8\n[90m# ... with 4 more variables: `9` [3m[90m<dbl>[90m[23m, `10` [3m[90m<dbl>[90m[23m,\n#   `11` [3m[90m<dbl>[90m[23m, `12` [3m[90m<dbl>[90m[23m[39m\n",
        "> ",
        "setNames(dfloo, dfsim$ID)",
        "$`1`\n Estimate        SE \n500.01917  47.65491 \n\n$`2`\n Estimate        SE \n354.15163  10.33634 \n\n$`3`\n Estimate        SE \n345.27274  27.38355 \n\n$`4`\n Estimate        SE \n313.54675  12.92343 \n\n$`5`\n Estimate        SE \n275.30720  13.17362 \n\n$`6`\n Estimate        SE \n276.97986  11.81379 \n\n$`7`\n Estimate        SE \n499.22377  47.85191 \n\n$`8`\n Estimate        SE \n354.86079  10.79267 \n\n$`9`\n Estimate        SE \n346.21457  25.94232 \n\n$`10`\n Estimate        SE \n315.67658  11.91492 \n\n$`11`\n Estimate        SE \n276.05242 ",
        " 12.51905 \n\n$`12`\n Estimate        SE \n277.75786  11.16051 \n\n",
        "> ",
        "class(setNames(dfloo, dfsim$ID))",
        "[1] \"list\"\n",
        "> ",
        "setNames(dfloo, dfsim$ID)[[1]]",
        " Estimate        SE \n500.01917  47.65491 \n",
        "> ",
        "dfloo <- dout$model %>%",
        "+ ",
        "  map(~loo(.x)$estimates) %>%",
        "+ ",
        "  setNames(dfsim$ID) %>%",
        "+ ",
        "  bind_rows(.id = \"ID\")",
        "> ",
        "dfloo",
        "> ",
        "dfloo",
        "[90m# A tibble: 6 x 13[39m\n  ID        `1`      `2`     `3`      `4`      `5`\n  [3m[90m<chr>[39m[23m   [3m[90m<dbl>[39m[23m    [3m[90m<dbl>[39m[23m   [3m[90m<dbl>[39m[23m    [3m[90m<dbl>[39m[23m    [3m[90m<dbl>[39m[23m\n[90m1[39m 1     -[31m250[39m[31m.[39m   -[31m177[39m[31m.[39m    -[31m173[39m[31m.[39m   -[31m157[39m[31m.[39m    -[31m138[39m[31m.[39m   \n[90m2[39m 1       12.6     2.79     6.11    3.01     3.46 \n[90m3[39m 1      500.    354.     345.    314.     275.   \n",
        "[90m4[39m 1       23.8     5.17    13.7     6.46     6.59 \n[90m5[39m 1        2.99    0.515    1.62    0.794    0.836\n[90m6[39m 1       47.7    10.3     27.4    12.9     13.2  \n[90m# ... with 7 more variables: `6` [3m[90m<dbl>[90m[23m, `7` [3m[90m<dbl>[90m[23m,\n#   `8` [3m[90m<dbl>[90m[23m, `9` [3m[90m<dbl>[90m[23m, `10` [3m[90m<dbl>[90m[23m, `11` [3m[90m<dbl>[90m[23m,\n#   `12` [3m[90m<dbl>[90m[23m[39m\n",
        "> ",
        "dfloo <- dout$model %>%",
        "+ ",
        "  map(~loo(.x)$estimates)",
        "> ",
        "dfloo",
        "[[1]]\n           Estimate        SE\nelpd_loo -250.00958 23.827457\np_loo      12.64425  2.991601\nlooic     500.01917 47.654913\n\n[[2]]\n            Estimate         SE\nelpd_loo -177.075815  5.1681690\np_loo       2.786279  0.5149173\nlooic     354.151629 10.3363379\n\n[[3]]\n            Estimate        SE\nelpd_loo -172.636371 13.691775\np_loo       6.112973  1.617438\nlooic     345.272741 27.383550\n\n[[4]]\n            Estimate         SE\nelpd_loo -156.773374  6.4617161\np_loo       3.013884  0.7938226\nlooic     313.546748",
        " 12.9234322\n\n[[5]]\n            Estimate         SE\nelpd_loo -137.653601  6.5868103\np_loo       3.455958  0.8363403\nlooic     275.307202 13.1736207\n\n[[6]]\n            Estimate         SE\nelpd_loo -138.489932  5.9068954\np_loo       3.164131  0.7935355\nlooic     276.979863 11.8137908\n\n[[7]]\n           Estimate       SE\nelpd_loo -249.61189 23.92596\np_loo      11.82523  2.79823\nlooic     499.22377 47.85191\n\n[[8]]\n            Estimate         SE\nelpd_loo -177.430397  5.3963329\np_loo       2.464451  0.4493044\nlooic   ",
        "  354.860795 10.7926657\n\n[[9]]\n           Estimate        SE\nelpd_loo -173.10728 12.971160\np_loo       6.03774  1.529681\nlooic     346.21457 25.942320\n\n[[10]]\n            Estimate         SE\nelpd_loo -157.838290  5.9574620\np_loo       2.887305  0.6469958\nlooic     315.676580 11.9149241\n\n[[11]]\n            Estimate         SE\nelpd_loo -138.026208  6.2595256\np_loo       3.317681  0.7453538\nlooic     276.052416 12.5190512\n\n[[12]]\n            Estimate         SE\nelpd_loo -138.878928  5.5802559\np_loo       2.929671",
        "  0.6831397\nlooic     277.757855 11.1605118\n\n",
        "> ",
        "dfloo[[12]]",
        "            Estimate         SE\nelpd_loo -138.878928  5.5802559\np_loo       2.929671  0.6831397\nlooic     277.757855 11.1605118\n",
        "> ",
        "class(dfloo[[12]])",
        "[1] \"matrix\"\n",
        "> ",
        "dfloo <- dout$model %>%",
        "+ ",
        "  map(~data.frame(loo(.x)$estimates)) %>%",
        "+ ",
        "  setNames(dfsim$ID) %>%",
        "+ ",
        "  bind_rows(.id = \"ID\")",
        "> ",
        "dfloo",
        "   ID    Estimate         SE\n1   1 -250.009585 23.8274565\n2   1   12.644246  2.9916008\n3   1  500.019169 47.6549130\n4   2 -177.075815  5.1681690\n5   2    2.786279  0.5149173\n6   2  354.151629 10.3363379\n7   3 -172.636371 13.6917750\n8   3    6.112973  1.6174383\n9   3  345.272741 27.3835499\n10  4 -156.773374  6.4617161\n11  4    3.013884  0.7938226\n12  4  313.546748 12.9234322\n13  5 -137.653601  6.5868103\n14  5    3.455958  0.8363403\n15  5  275.307202 13.1736207\n16  6 -138.489932  5.9068954\n17  6    3.164131  0.7935355",
        "\n18  6  276.979863 11.8137908\n19  7 -249.611885 23.9259572\n20  7   11.825226  2.7982302\n21  7  499.223771 47.8519144\n22  8 -177.430397  5.3963329\n23  8    2.464451  0.4493044\n24  8  354.860795 10.7926657\n25  9 -173.107285 12.9711602\n26  9    6.037740  1.5296813\n27  9  346.214569 25.9423204\n28 10 -157.838290  5.9574620\n29 10    2.887305  0.6469958\n30 10  315.676580 11.9149241\n31 11 -138.026208  6.2595256\n32 11    3.317681  0.7453538\n33 11  276.052416 12.5190512\n34 12 -138.878928  5.5802559\n35 12    2.929671  0.6831397",
        "\n36 12  277.757855 11.1605118\n",
        "> ",
        "dfloo <- dout$model %>%",
        "+ ",
        "  map(~data.frame(loo(.x)$estimates[3,])) %>%",
        "+ ",
        "  setNames(dfsim$ID) %>%",
        "+ ",
        "  bind_rows(.id = \"ID\")",
        "> ",
        "dfloo",
        "   ID loo..x..estimates.3...\n1   1              500.01917\n2   1               47.65491\n3   2              354.15163\n4   2               10.33634\n5   3              345.27274\n6   3               27.38355\n7   4              313.54675\n8   4               12.92343\n9   5              275.30720\n10  5               13.17362\n11  6              276.97986\n12  6               11.81379\n13  7              499.22377\n14  7               47.85191\n15  8              354.86079\n16  8               10.79267\n17  9              346.21457",
        "\n18  9               25.94232\n19 10              315.67658\n20 10               11.91492\n21 11              276.05242\n22 11               12.51905\n23 12              277.75786\n24 12               11.16051\n",
        "> ",
        "dfloo <- dout$model %>%",
        "+ ",
        "  map(~data.frame(loo(.x)$estimates[3,1])) %>%",
        "+ ",
        "  setNames(dfsim$ID) %>%",
        "+ ",
        "  bind_rows(.id = \"ID\")",
        "> ",
        "dfloo",
        "   ID loo..x..estimates.3..1.\n1   1                500.0192\n2   2                354.1516\n3   3                345.2727\n4   4                313.5467\n5   5                275.3072\n6   6                276.9799\n7   7                499.2238\n8   8                354.8608\n9   9                346.2146\n10 10                315.6766\n11 11                276.0524\n12 12                277.7579\n",
        "> ",
        "which.min(dfloo$loo..x..estimates.3..1.)",
        "[1] 5\n",
        "> ",
        "datsim[which.min(dfloo$loo..x..estimates.3..1.),]",
        "Error: object 'datsim' not found\n",
        "> ",
        "dfsim[which.min(dfloo$loo..x..estimates.3..1.),]",
        "> ",
        "dfsim[which.min(dfloo$loo..x..estimates.3..1.),]",
        "> ",
        "dout",
        "[90m# A tibble: 12 x 5[39m\n   family  form   prior      ID model\n   [3m[90m<chr>[39m[23m   [3m[90m<chr>[39m[23m  [3m[90m<chr>[39m[23m   [3m[90m<int>[39m[23m [3m[90m<lis>[39m[23m\n[90m 1[39m poisson y~ x1  normal~     1 [90m<brm[0m~\n[90m 2[39m negbin~ y~ x1  normal~     2 [90m<brm[0m~\n[90m 3[39m poisson y~x2   normal~     3 [90m<brm[0m~\n[90m 4[39m negbin~ y~x2   normal~     4 [90m<brm[0m~\n[90m 5[39m poisson y ~x1~ normal~     5 [90m<brm[0m~\n[90m 6[39m negbin~ y ~x1~ normal~     6 [90m<brm[0m~\n",
        "[90m 7[39m poisson y~ x1  normal~     7 [90m<brm[0m~\n[90m 8[39m negbin~ y~ x1  normal~     8 [90m<brm[0m~\n[90m 9[39m poisson y~x2   normal~     9 [90m<brm[0m~\n[90m10[39m negbin~ y~x2   normal~    10 [90m<brm[0m~\n[90m11[39m poisson y ~x1~ normal~    11 [90m<brm[0m~\n[90m12[39m negbin~ y ~x1~ normal~    12 [90m<brm[0m~\n",
        "> ",
        "dout$model[[1]]",
        " Family: poisson \n  Links: mu = log \nFormula: y ~ x1 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept     1.93      0.10     1.74     2.12 1.00     1852\nx1            1.36      0.14     1.08     1.64 1.00     2015\n          Tail_ESS\nIntercept     2187\nx1            2339\n\nSamples were drawn using sampling(NUTS). ",
        "For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n",
        "> ",
        "dfsim",
        "[90m# A tibble: 12 x 4[39m\n   family    form     prior        ID\n   [3m[90m<chr>[39m[23m     [3m[90m<chr>[39m[23m    [3m[90m<chr>[39m[23m     [3m[90m<int>[39m[23m\n[90m 1[39m poisson   y~ x1    normal(0~     1\n[90m 2[39m negbinom~ y~ x1    normal(0~     2\n[90m 3[39m poisson   y~x2     normal(0~     3\n[90m 4[39m negbinom~ y~x2     normal(0~     4\n[90m 5[39m poisson   y ~x1 +~ normal(0~     5\n[90m 6[39m negbinom~ y ~x1 +~ normal(0~     6\n[90m 7[39m poisson   y~ x1    normal(0~     7\n",
        "[90m 8[39m negbinom~ y~ x1    normal(0~     8\n[90m 9[39m poisson   y~x2     normal(0~     9\n[90m10[39m negbinom~ y~x2     normal(0~    10\n[90m11[39m poisson   y ~x1 +~ normal(0~    11\n[90m12[39m negbinom~ y ~x1 +~ normal(0~    12\n",
        "> ",
        "dout$model[[2]]",
        " Family: negbinomial \n  Links: mu = log; shape = identity \nFormula: y ~ x1 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept     1.99      0.20     1.61     2.38 1.00     3392\nx1            1.28      0.32     0.68     1.90 1.00     3416\n          Tail_ESS\nIntercept     2652\nx1            2536\n\nFamily Specific Parameters: \n",
        "      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nshape     3.34      0.84     2.00     5.19 1.00     3704\n      Tail_ESS\nshape     3155\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n",
        "> ",
        "dout$model[[1]]",
        " Family: poisson \n  Links: mu = log \nFormula: y ~ x1 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept     1.93      0.10     1.74     2.12 1.00     1852\nx1            1.36      0.14     1.08     1.64 1.00     2015\n          Tail_ESS\nIntercept     2187\nx1            2339\n\nSamples were drawn using sampling(NUTS). ",
        "For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n",
        "> ",
        "dout$model[[2]]",
        " Family: negbinomial \n  Links: mu = log; shape = identity \nFormula: y ~ x1 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept     1.99      0.20     1.61     2.38 1.00     3392\nx1            1.28      0.32     0.68     1.90 1.00     3416\n          Tail_ESS\nIntercept     2652\nx1            2536\n\nFamily Specific Parameters: \n",
        "      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nshape     3.34      0.84     2.00     5.19 1.00     3704\n      Tail_ESS\nshape     3155\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n",
        "> ",
        "dout$model[[2]]$ranef",
        " [1] id    group gn    coef  cn    resp  dpar  nlpar ggn   cor  \n[11] type  form \n<0 rows> (or 0-length row.names)\n",
        "> ",
        "dout$model[[2]]$family",
        "\nFamily: negbinomial \nLink function: log \n\n",
        "> ",
        "dout$model[[2]]$fit",
        "Inference for Stan model: 3b6956eb5bf7ab30be037c102479916b.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n               mean se_mean   sd    2.5%     25%     50%\nb_Intercept    1.99    0.00 0.20    1.61    1.85    1.99\nb_x1           1.28    0.01 0.32    0.68    1.06    1.27\nshape          3.34    0.01 0.84    2.00    2.74    3.24\nIntercept      2.68    0.00 0.09    2.51    2.62    2.68\nlp__        -186.79    0.03 1.23 -189.87 -187.35 -186.48",
        "\n                75%   97.5% n_eff Rhat\nb_Intercept    2.13    2.38  3385    1\nb_x1           1.49    1.90  3396    1\nshape          3.82    5.19  3599    1\nIntercept      2.74    2.86  3982    1\nlp__        -185.89 -185.38  1917    1\n\nSamples were drawn using NUTS(diag_e) at Sun Feb 16 13:36:06 2020.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n",
        "> ",
        "dout$model[[2]]$fit %>% class()",
        "[1] \"stanfit\"\nattr(,\"package\")\n[1] \"rstan\"\n",
        "> ",
        "data.frame(dout$model[[2]]$fit)",
        "Error in .local(object, ...) : unused argument (optional = TRUE)\n",
        "> ",
        "str(dout$model[[2]]$fit)",
        "Formal class 'stanfit' [package \"rstan\"] with 10 slots\n  ..@ model_name: chr \"3b6956eb5bf7ab30be037c102479916b\"\n  ..@ model_pars: chr [1:5] \"b\" \"Intercept\" \"shape\" \"b_Intercept\" ...\n  ..@ par_dims  :List of 5\n  .. ..$ b          : num 1\n  .. ..$ Intercept  : num(0) \n  .. ..$ shape      : num(0) \n  .. ..$ b_Intercept: num(0) \n  .. ..$ lp__       : num(0) \n  ..@ mode      : int 0\n  ..@ sim       :List of 15\n  .. ..$ samples      :List of 4\n  .. .. ..$ :List of 5\n  .. .. .. ..$ b_Intercept: num [1:2000] 0.946 0.946 0.946 0.946 0.976",
        " ...\n  .. .. .. ..$ b_x1       : num [1:2000] 1.42 1.42 1.42 1.42 1.42 ...\n  .. .. .. ..$ shape      : num [1:2000] 4.84 4.84 4.84 4.84 4.59 ...\n  .. .. .. ..$ Intercept  : num [1:2000] 1.71 1.71 1.71 1.71 1.74 ...\n  .. .. .. ..$ lp__       : num [1:2000] -280 -280 -280 -280 -271 ...\n  .. .. .. ..- attr(*, \"test_grad\")= logi FALSE\n  .. .. .. ..- attr(*, \"args\")=List of 16\n  .. .. .. .. ..$ append_samples    : logi FALSE\n  .. .. .. .. ..$ chain_id          : num 1\n  .. .. .. .. ..$ control           :List of ",
        "12\n  .. .. .. .. .. ..$ adapt_delta      : num 0.8\n  .. .. .. .. .. ..$ adapt_engaged    : logi TRUE\n  .. .. .. .. .. ..$ adapt_gamma      : num 0.05\n  .. .. .. .. .. ..$ adapt_init_buffer: num 75\n  .. .. .. .. .. ..$ adapt_kappa      : num 0.75\n  .. .. .. .. .. ..$ adapt_t0         : num 10\n  .. .. .. .. .. ..$ adapt_term_buffer: num 50\n  .. .. .. .. .. ..$ adapt_window     : num 25\n  .. .. .. .. .. ..$ max_treedepth    : int 10\n  .. .. .. .. .. ..$ metric           : chr \"diag_e\"\n  .. .. .. .. .. ..$ stepsize         ",
        ": num 1\n  .. .. .. .. .. ..$ stepsize_jitter  : num 0\n  .. .. .. .. ..$ enable_random_init: logi TRUE\n  .. .. .. .. ..$ init              : chr \"random\"\n  .. .. .. .. ..$ init_list         : NULL\n  .. .. .. .. ..$ init_radius       : num 2\n  .. .. .. .. ..$ iter              : int 2000\n  .. .. .. .. ..$ method            : chr \"sampling\"\n  .. .. .. .. ..$ random_seed       : chr \"2143557857\"\n  .. .. .. .. ..$ refresh           : int 200\n  .. .. .. .. ..$ sampler_t         : chr \"NUTS(diag_e)\"\n  .. .. .. .. ..",
        "$ save_warmup       : logi TRUE\n  .. .. .. .. ..$ test_grad         : logi FALSE\n  .. .. .. .. ..$ thin              : int 1\n  .. .. .. .. ..$ warmup            : int 1000\n  .. .. .. ..- attr(*, \"inits\")= num [1:4] 1.3214 0.7814 6.8928 0.0669\n  .. .. .. ..- attr(*, \"mean_pars\")= num [1:4] 1.28 2.68 3.3 1.99\n  .. .. .. ..- attr(*, \"mean_lp__\")= num -187\n  .. .. .. ..- attr(*, \"adaptation_info\")= chr \"# Adaptation terminated\\n# Step size = 0.749738\\n# Diagonal elements of inverse mass matrix:\\n# 0.0853259, 0.00\"| __truncated__",
        "\n  .. .. .. ..- attr(*, \"elapsed_time\")= Named num [1:2] 0.129 0.125\n  .. .. .. .. ..- attr(*, \"names\")= chr [1:2] \"warmup\" \"sample\"\n  .. .. .. ..- attr(*, \"sampler_params\")=List of 6\n  .. .. .. .. ..$ accept_stat__: num [1:2000] 1.00 0.00 0.00 5.96e-210 1.00 ...\n  .. .. .. .. ..$ stepsize__   : num [1:2000] 0.0625 14.3855 2.4312 0.2398 0.0186 ...\n  .. .. .. .. ..$ treedepth__  : num [1:2000] 1 0 0 1 2 2 2 2 2 4 ...\n  .. .. .. .. ..$ n_leapfrog__ : num [1:2000] 1 1 1 3 3 3 3 3 7 31 ...\n  .. .. .. .. ..$ divergent__  ",
        ": num [1:2000] 0 1 1 1 0 0 0 0 0 0 ...\n  .. .. .. .. ..$ energy__     : num [1:2000] 539 282 281 283 283 ...\n  .. .. .. ..- attr(*, \"return_code\")= int 0\n  .. .. ..$ :List of 5\n  .. .. .. ..$ b_Intercept: num [1:2000] 0.16 0.16 0.16 0.16 0.709 ...\n  .. .. .. ..$ b_x1       : num [1:2000] -1.35 -1.35 -1.35 -1.35 -1.28 ...\n  .. .. .. ..$ shape      : num [1:2000] 0.17 0.17 0.17 0.17 0.096 ...\n  .. .. .. ..$ Intercept  : num [1:2000] -0.5702 -0.5702 -0.5702 -0.5702 0.0153 ...\n  .. .. .. ..$ lp__       : num [1:2000] ",
        "-450 -450 -450 -450 -333 ...\n  .. .. .. ..- attr(*, \"test_grad\")= logi FALSE\n  .. .. .. ..- attr(*, \"args\")=List of 16\n  .. .. .. .. ..$ append_samples    : logi FALSE\n  .. .. .. .. ..$ chain_id          : num 2\n  .. .. .. .. ..$ control           :List of 12\n  .. .. .. .. .. ..$ adapt_delta      : num 0.8\n  .. .. .. .. .. ..$ adapt_engaged    : logi TRUE\n  .. .. .. .. .. ..$ adapt_gamma      : num 0.05\n  .. .. .. .. .. ..$ adapt_init_buffer: num 75\n  .. .. .. .. .. ..$ adapt_kappa      : num 0.75\n  .. .. .. .. .. ..",
        "$ adapt_t0         : num 10\n  .. .. .. .. .. ..$ adapt_term_buffer: num 50\n  .. .. .. .. .. ..$ adapt_window     : num 25\n  .. .. .. .. .. ..$ max_treedepth    : int 10\n  .. .. .. .. .. ..$ metric           : chr \"diag_e\"\n  .. .. .. .. .. ..$ stepsize         : num 1\n  .. .. .. .. .. ..$ stepsize_jitter  : num 0\n  .. .. .. .. ..$ enable_random_init: logi TRUE\n  .. .. .. .. ..$ init              : chr \"random\"\n  .. .. .. .. ..$ init_list         : NULL\n  .. .. .. .. ..$ init_radius       : num 2\n  .. .. .. .. ..",
        "$ iter              : int 2000\n  .. .. .. .. ..$ method            : chr \"sampling\"\n  .. .. .. .. ..$ random_seed       : chr \"2143557857\"\n  .. .. .. .. ..$ refresh           : int 200\n  .. .. .. .. ..$ sampler_t         : chr \"NUTS(diag_e)\"\n  .. .. .. .. ..$ save_warmup       : logi TRUE\n  .. .. .. .. ..$ test_grad         : logi FALSE\n  .. .. .. .. ..$ thin              : int 1\n  .. .. .. .. ..$ warmup            : int 1000\n  .. .. .. ..- attr(*, \"inits\")= num [1:4] -1.487 -1.618 0.375 -0.814\n  .. .. .. ..",
        "- attr(*, \"mean_pars\")= num [1:4] 1.28 2.68 3.33 1.99\n  .. .. .. ..- attr(*, \"mean_lp__\")= num -187\n  .. .. .. ..- attr(*, \"adaptation_info\")= chr \"# Adaptation terminated\\n# Step size = 0.727295\\n# Diagonal elements of inverse mass matrix:\\n# 0.0849771, 0.00\"| __truncated__\n  .. .. .. ..- attr(*, \"elapsed_time\")= Named num [1:2] 0.119 0.139\n  .. .. .. .. ..- attr(*, \"names\")= chr [1:2] \"warmup\" \"sample\"\n  .. .. .. ..- attr(*, \"sampler_params\")=List of 6\n  .. .. .. .. ..$ accept_stat__: num [1:2000] 1.00 0.00 0.00 6.43e-133 1.00",
        " ...\n  .. .. .. .. ..$ stepsize__   : num [1:2000] 0.0625 14.3855 2.4312 0.2398 0.0186 ...\n  .. .. .. .. ..$ treedepth__  : num [1:2000] 1 0 0 2 4 2 3 4 2 2 ...\n  .. .. .. .. ..$ n_leapfrog__ : num [1:2000] 1 1 1 3 15 3 7 15 3 3 ...\n  .. .. .. .. ..$ divergent__  : num [1:2000] 0 1 1 0 0 0 0 0 0 0 ...\n  .. .. .. .. ..$ energy__     : num [1:2000] 860 450 451 450 450 ...\n  .. .. .. ..- attr(*, \"return_code\")= int 0\n  .. .. ..$ :List of 5\n  .. .. .. ..$ b_Intercept: num [1:2000] 4.31 4.31 4.31 2.48 2.48 ...\n  .. .. .. ..",
        "$ b_x1       : num [1:2000] -0.6551 -0.6551 -0.6551 -0.0305 -0.0305 ...\n  .. .. .. ..$ shape      : num [1:2000] 0.177 0.177 0.177 2.94 2.94 ...\n  .. .. .. ..$ Intercept  : num [1:2000] 3.95 3.95 3.95 2.47 2.47 ...\n  .. .. .. ..$ lp__       : num [1:2000] -249 -249 -249 -199 -199 ...\n  .. .. .. ..- attr(*, \"test_grad\")= logi FALSE\n  .. .. .. ..- attr(*, \"args\")=List of 16\n  .. .. .. .. ..$ append_samples    : logi FALSE\n  .. .. .. .. ..$ chain_id          : num 3\n  .. .. .. .. ..$ control           :List of ",
        "12\n  .. .. .. .. .. ..$ adapt_delta      : num 0.8\n  .. .. .. .. .. ..$ adapt_engaged    : logi TRUE\n  .. .. .. .. .. ..$ adapt_gamma      : num 0.05\n  .. .. .. .. .. ..$ adapt_init_buffer: num 75\n  .. .. .. .. .. ..$ adapt_kappa      : num 0.75\n  .. .. .. .. .. ..$ adapt_t0         : num 10\n  .. .. .. .. .. ..$ adapt_term_buffer: num 50\n  .. .. .. .. .. ..$ adapt_window     : num 25\n  .. .. .. .. .. ..$ max_treedepth    : int 10\n  .. .. .. .. .. ..$ metric           : chr \"diag_e\"\n  .. .. .. .. .. ..$ stepsize         ",
        ": num 1\n  .. .. .. .. .. ..$ stepsize_jitter  : num 0\n  .. .. .. .. ..$ enable_random_init: logi TRUE\n  .. .. .. .. ..$ init              : chr \"random\"\n  .. .. .. .. ..$ init_list         : NULL\n  .. .. .. .. ..$ init_radius       : num 2\n  .. .. .. .. ..$ iter              : int 2000\n  .. .. .. .. ..$ method            : chr \"sampling\"\n  .. .. .. .. ..$ random_seed       : chr \"2143557857\"\n  .. .. .. .. ..$ refresh           : int 200\n  .. .. .. .. ..$ sampler_t         : chr \"NUTS(diag_e)\"\n  .. .. .. .. ..",
        "$ save_warmup       : logi TRUE\n  .. .. .. .. ..$ test_grad         : logi FALSE\n  .. .. .. .. ..$ thin              : int 1\n  .. .. .. .. ..$ warmup            : int 1000\n  .. .. .. ..- attr(*, \"inits\")= num [1:4] -1.39 -1.75 4.39 -1\n  .. .. .. ..- attr(*, \"mean_pars\")= num [1:4] 1.27 2.69 3.39 2\n  .. .. .. ..- attr(*, \"mean_lp__\")= num -187\n  .. .. .. ..- attr(*, \"adaptation_info\")= chr \"# Adaptation terminated\\n# Step size = 0.830292\\n# Diagonal elements of inverse mass matrix:\\n# 0.0817563, 0.00\"| __truncated__",
        "\n  .. .. .. ..- attr(*, \"elapsed_time\")= Named num [1:2] 0.133 0.177\n  .. .. .. .. ..- attr(*, \"names\")= chr [1:2] \"warmup\" \"sample\"\n  .. .. .. ..- attr(*, \"sampler_params\")=List of 6\n  .. .. .. .. ..$ accept_stat__: num [1:2000] 1.00 0.00 0.00 1.00 5.36e-33 ...\n  .. .. .. .. ..$ stepsize__   : num [1:2000] 0.125 14.386 2.431 0.24 0.324 ...\n  .. .. .. .. ..$ treedepth__  : num [1:2000] 1 0 0 2 2 3 4 3 4 2 ...\n  .. .. .. .. ..$ n_leapfrog__ : num [1:2000] 1 1 1 3 5 7 15 7 19 3 ...\n  .. .. .. .. ..$ divergent__  ",
        ": num [1:2000] 0 1 1 0 1 0 0 0 0 0 ...\n  .. .. .. .. ..$ energy__     : num [1:2000] 1575 251 253 234 200 ...\n  .. .. .. ..- attr(*, \"return_code\")= int 0\n  .. .. ..$ :List of 5\n  .. .. .. ..$ b_Intercept: num [1:2000] 5.47 5.47 5.47 4.72 4.72 ...\n  .. .. .. ..$ b_x1       : num [1:2000] -0.69 -0.69 -0.69 -0.76 -0.76 ...\n  .. .. .. ..$ shape      : num [1:2000] 0.598 0.598 0.598 0.461 0.461 ...\n  .. .. .. ..$ Intercept  : num [1:2000] 5.1 5.1 5.1 4.31 4.31 ...\n  .. .. .. ..$ lp__       : num [1:2000] -253 -253 -253 -234 -234",
        " ...\n  .. .. .. ..- attr(*, \"test_grad\")= logi FALSE\n  .. .. .. ..- attr(*, \"args\")=List of 16\n  .. .. .. .. ..$ append_samples    : logi FALSE\n  .. .. .. .. ..$ chain_id          : num 4\n  .. .. .. .. ..$ control           :List of 12\n  .. .. .. .. .. ..$ adapt_delta      : num 0.8\n  .. .. .. .. .. ..$ adapt_engaged    : logi TRUE\n  .. .. .. .. .. ..$ adapt_gamma      : num 0.05\n  .. .. .. .. .. ..$ adapt_init_buffer: num 75\n  .. .. .. .. .. ..$ adapt_kappa      : num 0.75\n  .. .. .. .. .. ..$ adapt_t0         ",
        ": num 10\n  .. .. .. .. .. ..$ adapt_term_buffer: num 50\n  .. .. .. .. .. ..$ adapt_window     : num 25\n  .. .. .. .. .. ..$ max_treedepth    : int 10\n  .. .. .. .. .. ..$ metric           : chr \"diag_e\"\n  .. .. .. .. .. ..$ stepsize         : num 1\n  .. .. .. .. .. ..$ stepsize_jitter  : num 0\n  .. .. .. .. ..$ enable_random_init: logi TRUE\n  .. .. .. .. ..$ init              : chr \"random\"\n  .. .. .. .. ..$ init_list         : NULL\n  .. .. .. .. ..$ init_radius       : num 2\n  .. .. .. .. ..$ iter              ",
        ": int 2000\n  .. .. .. .. ..$ method            : chr \"sampling\"\n  .. .. .. .. ..$ random_seed       : chr \"2143557857\"\n  .. .. .. .. ..$ refresh           : int 200\n  .. .. .. .. ..$ sampler_t         : chr \"NUTS(diag_e)\"\n  .. .. .. .. ..$ save_warmup       : logi TRUE\n  .. .. .. .. ..$ test_grad         : logi FALSE\n  .. .. .. .. ..$ thin              : int 1\n  .. .. .. .. ..$ warmup            : int 1000\n  .. .. .. ..- attr(*, \"inits\")= num [1:4] -1.649 0.14 0.137 1.032\n  .. .. .. ..- attr(*, \"mean_pars\")=",
        " num [1:4] 1.28 2.68 3.32 1.99\n  .. .. .. ..- attr(*, \"mean_lp__\")= num -187\n  .. .. .. ..- attr(*, \"adaptation_info\")= chr \"# Adaptation terminated\\n# Step size = 0.898002\\n# Diagonal elements of inverse mass matrix:\\n# 0.092413, 0.007\"| __truncated__\n  .. .. .. ..- attr(*, \"elapsed_time\")= Named num [1:2] 0.141 0.098\n  .. .. .. .. ..- attr(*, \"names\")= chr [1:2] \"warmup\" \"sample\"\n  .. .. .. ..- attr(*, \"sampler_params\")=List of 6\n  .. .. .. .. ..$ accept_stat__: num [1:2000] 1 0 0 0.86 0.814 ...\n  .. .. .. .. ..",
        "$ stepsize__   : num [1:2000] 0.125 14.386 2.431 0.24 0.217 ...\n  .. .. .. .. ..$ treedepth__  : num [1:2000] 3 0 0 2 1 2 4 4 3 2 ...\n  .. .. .. .. ..$ n_leapfrog__ : num [1:2000] 7 1 1 3 1 3 23 15 15 3 ...\n  .. .. .. .. ..$ divergent__  : num [1:2000] 0 1 1 0 0 0 0 0 0 0 ...\n  .. .. .. .. ..$ energy__     : num [1:2000] 322 253 255 248 234 ...\n  .. .. .. ..- attr(*, \"return_code\")= int 0\n  .. ..$ iter         : num 2000\n  .. ..$ thin         : num 1\n  .. ..$ warmup       : num 1000\n  .. ..$ chains       : num ",
        "4\n  .. ..$ n_save       : num [1:4] 2000 2000 2000 2000\n  .. ..$ warmup2      : num [1:4] 1000 1000 1000 1000\n  .. ..$ permutation  :List of 4\n  .. .. ..$ : int [1:1000] 2 909 905 475 154 290 432 749 421 362 ...\n  .. .. ..$ : int [1:1000] 418 15 236 891 225 856 996 850 963 531 ...\n  .. .. ..$ : int [1:1000] 856 843 694 805 698 637 575 133 114 448 ...\n  .. .. ..$ : int [1:1000] 443 713 336 775 948 550 295 45 365 794 ...\n  .. ..$ pars_oi      : chr [1:5] \"b_Intercept\" \"b\" \"shape\" \"Intercept\" ...\n  .. ..$ dims_oi      ",
        ":List of 5\n  .. .. ..$ b_Intercept: num(0) \n  .. .. ..$ b          : num 1\n  .. .. ..$ shape      : num(0) \n  .. .. ..$ Intercept  : num(0) \n  .. .. ..$ lp__       : num(0) \n  .. ..$ fnames_oi    : chr [1:5] \"b_Intercept\" \"b_x1\" \"shape\" \"Intercept\" ...\n  .. ..$ n_flatnames  : int 5\n  .. ..$ pars_oi_old  : chr [1:5] \"b\" \"Intercept\" \"shape\" \"b_Intercept\" ...\n  .. ..$ dims_oi_old  :List of 5\n  .. .. ..$ b          : num 1\n  .. .. ..$ Intercept  : num(0) \n  .. .. ..$ shape      : num(0) \n  .. .. ..$ b_Intercept",
        ": num(0) \n  .. .. ..$ lp__       : num(0) \n  .. ..$ fnames_oi_old: chr [1:5] \"b[1]\" \"Intercept\" \"shape\" \"b_Intercept\" ...\n  ..@ inits     :List of 4\n  .. ..$ :List of 4\n  .. .. ..$ b          : num [1(1d)] 1.32\n  .. .. ..$ Intercept  : num 0.781\n  .. .. ..$ shape      : num 6.89\n  .. .. ..$ b_Intercept: num 0.0669\n  .. ..$ :List of 4\n  .. .. ..$ b          : num [1(1d)] -1.49\n  .. .. ..$ Intercept  : num -1.62\n  .. .. ..$ shape      : num 0.375\n  .. .. ..$ b_Intercept: num -0.814\n  .. ..$ :List of 4\n  .. .. ..",
        "$ b          : num [1(1d)] -1.39\n  .. .. ..$ Intercept  : num -1.75\n  .. .. ..$ shape      : num 4.39\n  .. .. ..$ b_Intercept: num -1\n  .. ..$ :List of 4\n  .. .. ..$ b          : num [1(1d)] -1.65\n  .. .. ..$ Intercept  : num 0.14\n  .. .. ..$ shape      : num 0.137\n  .. .. ..$ b_Intercept: num 1.03\n  ..@ stan_args :List of 4\n  .. ..$ :List of 8\n  .. .. ..$ chain_id : int 1\n  .. .. ..$ iter     : int 2000\n  .. .. ..$ thin     : int 1\n  .. .. ..$ seed     : int 2143557857\n  .. .. ..$ warmup   : num 1000\n  .. .. ..",
        "$ init     : chr \"random\"\n  .. .. ..$ algorithm: chr \"NUTS\"\n  .. .. ..$ method   : chr \"sampling\"\n  .. ..$ :List of 8\n  .. .. ..$ chain_id : int 2\n  .. .. ..$ iter     : int 2000\n  .. .. ..$ thin     : int 1\n  .. .. ..$ seed     : int 2143557857\n  .. .. ..$ warmup   : num 1000\n  .. .. ..$ init     : chr \"random\"\n  .. .. ..$ algorithm: chr \"NUTS\"\n  .. .. ..$ method   : chr \"sampling\"\n  .. ..$ :List of 8\n  .. .. ..$ chain_id : int 3\n  .. .. ..$ iter     : int 2000\n  .. .. ..$ thin     : int 1\n  .. .. ..$ seed     ",
        ": int 2143557857\n  .. .. ..$ warmup   : num 1000\n  .. .. ..$ init     : chr \"random\"\n  .. .. ..$ algorithm: chr \"NUTS\"\n  .. .. ..$ method   : chr \"sampling\"\n  .. ..$ :List of 8\n  .. .. ..$ chain_id : int 4\n  .. .. ..$ iter     : int 2000\n  .. .. ..$ thin     : int 1\n  .. .. ..$ seed     : int 2143557857\n  .. .. ..$ warmup   : num 1000\n  .. .. ..$ init     : chr \"random\"\n  .. .. ..$ algorithm: chr \"NUTS\"\n  .. .. ..$ method   : chr \"sampling\"\n  ..@ stanmodel :Formal class 'stanmodel' [package \"rstan\"] with 5 slots",
        "\n  .. .. ..@ model_name  : chr \"3b6956eb5bf7ab30be037c102479916b\"\n  .. .. ..@ model_code  : chr \"// generated with brms 2.11.1\\nfunctions {\\n}\\ndata {\\n  int<lower=1> N;  // number of observations\\n  int Y[N]\"| __truncated__\n  .. .. .. ..- attr(*, \"model_name2\")= chr \"3b6956eb5bf7ab30be037c102479916b\"\n  .. .. ..@ model_cpp   :List of 2\n  .. .. .. ..$ model_cppname: chr \"model126c6029588c_3b6956eb5bf7ab30be037c102479916b\"\n  .. .. .. ..$ model_cppcode: chr \"// Code generated by Stan version 2.19.1\\n\\n#include <stan/model/model_header.hpp>\\n\\nnamespace model126c602958\"| __truncated__",
        "\n  .. .. ..@ mk_cppmodule:function (object)  \n  .. .. ..@ dso         :Formal class 'cxxdso' [package \"rstan\"] with 7 slots\n  .. .. .. .. ..@ sig         :List of 1\n  .. .. .. .. .. ..$ file126c75b52c37: chr(0) \n  .. .. .. .. ..@ dso_saved   : logi TRUE\n  .. .. .. .. ..@ dso_filename: chr \"file126c75b52c37\"\n  .. .. .. .. ..@ modulename  : chr \"stan_fit4model126c6029588c_3b6956eb5bf7ab30be037c102479916b_mod\"\n  .. .. .. .. ..@ system      : chr \"x86_64, mingw32\"\n  .. .. .. .. ..@ cxxflags    : chr \"CXXFLAGS=-O3 -Wno-unused-variable -Wno-unused-function\"",
        "\n  .. .. .. .. ..@ .CXXDSOMISC :<environment: 0x000000002df14990> \n  ..@ date      : chr \"Sun Feb 16 13:36:06 2020\"\n  ..@ .MISC     :<environment: 0x0000000032820ea0> \n",
        "> ",
        "str(dout$model[[2]]$fit,1)",
        "Formal class 'stanfit' [package \"rstan\"] with 10 slots\n",
        "> ",
        "str(dout$model[[2]]$fit,2)",
        "Formal class 'stanfit' [package \"rstan\"] with 10 slots\n  ..@ model_name: chr \"3b6956eb5bf7ab30be037c102479916b\"\n  ..@ model_pars: chr [1:5] \"b\" \"Intercept\" \"shape\" \"b_Intercept\" ...\n  ..@ par_dims  :List of 5\n  ..@ mode      : int 0\n  ..@ sim       :List of 15\n  ..@ inits     :List of 4\n  ..@ stan_args :List of 4\n  ..@ stanmodel :Formal class 'stanmodel' [package \"rstan\"] with 5 slots\n  ..@ date      : chr \"Sun Feb 16 13:36:06 2020\"\n  ..@ .MISC     :<environment: 0x0000000032820ea0> \n",
        "> ",
        "dout$model[[2]]$fit@model_pars",
        "[1] \"b\"           \"Intercept\"   \"shape\"       \"b_Intercept\"\n[5] \"lp__\"       \n",
        "> ",
        "dout$model[[2]]$fit@mode",
        "[1] 0\n",
        "> ",
        "dout$model[[2]]$fit",
        "Inference for Stan model: 3b6956eb5bf7ab30be037c102479916b.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n               mean se_mean   sd    2.5%     25%     50%\nb_Intercept    1.99    0.00 0.20    1.61    1.85    1.99\nb_x1           1.28    0.01 0.32    0.68    1.06    1.27\nshape          3.34    0.01 0.84    2.00    2.74    3.24\nIntercept      2.68    0.00 0.09    2.51    2.62    2.68\nlp__        -186.79    0.03 1.23 -189.87 -187.35 -186.48",
        "\n                75%   97.5% n_eff Rhat\nb_Intercept    2.13    2.38  3385    1\nb_x1           1.49    1.90  3396    1\nshape          3.82    5.19  3599    1\nIntercept      2.74    2.86  3982    1\nlp__        -185.89 -185.38  1917    1\n\nSamples were drawn using NUTS(diag_e) at Sun Feb 16 13:36:06 2020.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n",
        "> ",
        "str(dout$model[[2]]$fit,1)",
        "Formal class 'stanfit' [package \"rstan\"] with 10 slots\n",
        "> ",
        "str(dout$model[[2]]$fit,2)",
        "Formal class 'stanfit' [package \"rstan\"] with 10 slots\n  ..@ model_name: chr \"3b6956eb5bf7ab30be037c102479916b\"\n  ..@ model_pars: chr [1:5] \"b\" \"Intercept\" \"shape\" \"b_Intercept\" ...\n  ..@ par_dims  :List of 5\n  ..@ mode      : int 0\n  ..@ sim       :List of 15\n  ..@ inits     :List of 4\n  ..@ stan_args :List of 4\n  ..@ stanmodel :Formal class 'stanmodel' [package \"rstan\"] with 5 slots\n  ..@ date      : chr \"Sun Feb 16 13:36:06 2020\"\n  ..@ .MISC     :<environment: 0x0000000032820ea0> \n",
        "> ",
        "?brm",
        "> ",
        "s1 <- summary(dout$model[[2]])",
        "> ",
        "str(s1, 1)",
        "List of 16\n $ formula  :List of 7\n  ..- attr(*, \"class\")= chr [1:2] \"brmsformula\" \"bform\"\n $ data.name: chr \"dat\"\n $ group    : chr(0) \n $ nobs     : int 50\n $ ngrps    : NULL\n $ autocor  : list()\n  ..- attr(*, \"class\")= chr [1:2] \"cor_empty\" \"cor_brms\"\n $ prior    :Classes brmsprior and 'data.frame':\t0 obs. of  8 variables:\n $ algorithm: chr \"sampling\"\n $ chains   : num 4\n $ iter     : num 2000\n $ warmup   : num 1000\n $ thin     : num 1\n $ sampler  : chr \"sampling(NUTS)\"\n $ fixed    : num [1:2, 1:7] ",
        "1.992 1.277 0.199 0.318 1.61 ...\n  ..- attr(*, \"dimnames\")=List of 2\n $ spec_pars: num [1, 1:7] 3.336 0.837 1.999 5.188 1 ...\n  ..- attr(*, \"dimnames\")=List of 2\n $ cor_pars : num[0 , 1:7] \n  ..- attr(*, \"dimnames\")=List of 2\n - attr(*, \"class\")= chr \"brmssummary\"\n",
        "> ",
        "s1$spec_pars",
        "      Estimate Est.Error l-95% CI u-95% CI\nshape 3.335704 0.8370359 1.999239 5.188184\n          Rhat Bulk_ESS Tail_ESS\nshape 1.000228     3704     3155\n",
        "> ",
        "summary(dout$model[[2]])$spec_pars[1,1]",
        "[1] 3.335704\n",
        "> ",
        "summary(dout$model[[1]])$spec_pars[1,1]",
        "Error in summary(dout$model[[1]])$spec_pars[1, 1] : \n  subscript out of bounds\n",
        "> ",
        "summary(dout$model[[1]])$spec_pars",
        "     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\n     Tail_ESS\n",
        "> ",
        "dout$family",
        " [1] \"poisson\"     \"negbinomial\"\n [3] \"poisson\"     \"negbinomial\"\n [5] \"poisson\"     \"negbinomial\"\n [7] \"poisson\"     \"negbinomial\"\n [9] \"poisson\"     \"negbinomial\"\n[11] \"poisson\"     \"negbinomial\"\n",
        "> ",
        "summary(dout$model[[2]])$spec_pars[1,1]",
        "[1] 3.335704\n",
        "> ",
        "dout$model[[1]]",
        " Family: poisson \n  Links: mu = log \nFormula: y ~ x1 \n   Data: dat (Number of observations: 50) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error\nIntercept     1.93      0.10\nx1            1.36      0.14\n          l-95% CI u-95% CI Rhat\nIntercept     1.74     2.12 1.00\nx1            1.08     1.64 1.00\n          Bulk_ESS Tail_ESS\nIntercept     1852     2187\nx1            2015     2339\n\nSamples were drawn using sampling(NUTS). ",
        "For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n",
        "> ",
        "class(dout$model[[1]])",
        "[1] \"brmsfit\"\n",
        "> ",
        "class(dout$model[1])",
        "[1] \"list\"\n",
        "> ",
        "class(dout$model[1][[1]])",
        "[1] \"brmsfit\"\n",
        "> ",
        "dsplots <- dout %>%",
        "+ ",
        "  group_by(ID) %>%",
        "+ ",
        "  with_groups({",
        "+ ",
        "    #Get shape param mean",
        "+ ",
        "    if (family == \"negbinomial\"){",
        "+ ",
        "      shape <- summary(model[[1]])$spec_pars[1,1]",
        "+ ",
        "    } else {",
        "+ ",
        "      shape <- NULL",
        "+ ",
        "    }",
        "+ ",
        "    ",
        "+ ",
        "    resids <- ds_resids(dat$y, ",
        "+ ",
        "                        #Note Mean estimate is in col 1 of ",
        "+ ",
        "                      #brms predict",
        "+ ",
        "                        predict(model[[1]])[,1], ",
        "+ ",
        "                        plot = FALSE, ",
        "+ ",
        "                        family = family, ",
        "+ ",
        "                        phis = shape)",
        "+ ",
        "    dsdf <- bind_cols(dat, ",
        "+ ",
        "                      fitted = predict(model[[1]])[,1],",
        "+ ",
        "                      resid = resids)",
        "+ ",
        "    g1 <- ggplot(dsdf) + ",
        "+ ",
        "      aes(x = fitted, y = resid, color = x2) + ",
        "+ ",
        "      geom_point()  +",
        "+ ",
        "      ggtitle(paste_(form, family, prior))",
        "+ ",
        "    #save plot to file ",
        "+ ",
        "    # ggsave(g1, file = paste0(\"figures/model-\", ID, \".png\"))",
        "+ ",
        "    list(g1)",
        "+ ",
        "  })",
        "Error in runif(n = length(yobs), min = a, max = b) : object 'b' not found\n",
        "> ",
        "#' Plot Dunn-Smyth residuals",
        "> ",
        "#'",
        "> ",
        "#' @Usage ds_resids(yobs, ypred, plotds = TRUE, ",
        "> ",
        "#' family = \"poisson\", phis = NULL)",
        "> ",
        "#'",
        "> ",
        "#' @param yobs numeric of observations",
        "> ",
        "#' @param ypred numeric of predictions",
        "> ",
        "#' @param plotds logical, should the residuals be plotted?",
        "> ",
        "#' @param family character for family (poisson, binomial, negbinomial or",
        "> ",
        "#'  nbinom)",
        "> ",
        "#' @param phis scale parameter for nbinom",
        "> ",
        "#'",
        "> ",
        "#' @return A Dunn-Smyth residuals and optionally, a plot of them.",
        "> ",
        "#' @Details Dunn-Smyth residuals are useful when checking for overdisperion or",
        "> ",
        "#' hetergenous variance in count models.  As for normal residual plots, you",
        "> ",
        "#' should look for fanning or evidence of non-linearities.",
        "> ",
        "#' Code is based on that from the boral package (boral::ds.residuals)",
        "> ",
        "#' This function is set-up for Poisson, Binomial and Negative binomial models. ",
        "> ",
        "#'",
        "> ",
        "#' @examples ",
        "> ",
        "#' data(InsectSprays)",
        "> ",
        "#' m1 <- glm(count ~ spray, family = \"poisson\", data = InsectSprays)",
        "> ",
        "#' InsectSprays$fit <- predict(m1, type = \"response\")",
        "> ",
        "#' with(InsectSprays, ",
        "> ",
        "#'   ds_resids(count, fit, family = \"poisson\"))",
        "> ",
        "#' #Looks good ",
        "> ",
        "#' ",
        "> ",
        "#' library(MASS)",
        "> ",
        "#' m2 <- glm.nb(count ~ spray, data = InsectSprays)",
        "> ",
        "#' InsectSprays$fit2 <- predict(m2, type = \"response\")",
        "> ",
        "#' with(InsectSprays, ",
        "> ",
        "#'   ds_resids(count, fit2, family = \"nbinom\", phis = 1/m2$theta))",
        "> ",
        "#'  #Ok good, note we need 1/theta to get phi ",
        "> ",
        "#'  ",
        "> ",
        "#' @author Christopher J. Brown",
        "> ",
        "#' @rdname ds_resids",
        "> ",
        "#' @export",
        "> ",
        "",
        "> ",
        "ds_resids <- function(yobs, ypred, plotds = TRUE, ",
        "+ ",
        "                          family = \"poisson\", ",
        "+ ",
        "                          phis = NULL, trial.size = 1){",
        "+ ",
        "  if (family == \"poisson\"){",
        "+ ",
        "    a <- ppois(yobs - 1, ypred)",
        "+ ",
        "    b <- ppois(yobs, ypred) ",
        "+ ",
        "  }",
        "+ ",
        "  if (family %in% c(\"nbinom\", \"negbinomial\")){",
        "+ ",
        "    a <- pnbinom(yobs - 1, mu = ypred, size = 1/phis)",
        "+ ",
        "    b <- pnbinom(yobs, mu = ypred, size = 1/phis) ",
        "+ ",
        "  }",
        "+ ",
        "  if (family == \"binomial\") {",
        "+ ",
        "    a <- pbinom(yobs - 1, ",
        "+ ",
        "                trial.size, prob = ypred)",
        "+ ",
        "    b <- pbinom(yobs, trial.size, ",
        "+ ",
        "                prob = ypred)",
        "+ ",
        "  }",
        "+ ",
        "  ",
        "+ ",
        "\tu <- runif(n = length(yobs), min = a, max = b)",
        "+ ",
        "\tdsres <- qnorm(u)",
        "+ ",
        "\tif (plotds){",
        "+ ",
        "\t\tpar(mfrow = c(1,2))",
        "+ ",
        "\t\tplot(ypred, dsres, ylab = \"Prediction\", xlab = \"Dunn-Smyth residual\")",
        "+ ",
        "\t\tabline(h=0)",
        "+ ",
        "\t\tqqnorm(dsres)",
        "+ ",
        "\t\tabline(0,1)",
        "+ ",
        "\t}",
        "+ ",
        "\treturn(dsres)",
        "+ ",
        "\t}",
        "> ",
        "dsplots <- dout %>%",
        "+ ",
        "  group_by(ID) %>%",
        "+ ",
        "  with_groups({",
        "+ ",
        "    #Get shape param mean",
        "+ ",
        "    if (family == \"negbinomial\"){",
        "+ ",
        "      shape <- summary(model[[1]])$spec_pars[1,1]",
        "+ ",
        "    } else {",
        "+ ",
        "      shape <- NULL",
        "+ ",
        "    }",
        "+ ",
        "    ",
        "+ ",
        "    resids <- ds_resids(dat$y, ",
        "+ ",
        "                        #Note Mean estimate is in col 1 of ",
        "+ ",
        "                      #brms predict",
        "+ ",
        "                        predict(model[[1]])[,1], ",
        "+ ",
        "                        plot = FALSE, ",
        "+ ",
        "                        family = family, ",
        "+ ",
        "                        phis = shape)",
        "+ ",
        "    dsdf <- bind_cols(dat, ",
        "+ ",
        "                      fitted = predict(model[[1]])[,1],",
        "+ ",
        "                      resid = resids)",
        "+ ",
        "    g1 <- ggplot(dsdf) + ",
        "+ ",
        "      aes(x = fitted, y = resid, color = x2) + ",
        "+ ",
        "      geom_point()  +",
        "+ ",
        "      ggtitle(paste_(form, family, prior))",
        "+ ",
        "    #save plot to file ",
        "+ ",
        "    # ggsave(g1, file = paste0(\"figures/model-\", ID, \".png\"))",
        "+ ",
        "    list(g1)",
        "+ ",
        "  })",
        "> ",
        "dsplots[[1]]",
        "[[1]]\n\n",
        "> ",
        "dsplots[[2]]",
        "[[1]]\n\n",
        "> ",
        "dsplots[[3]]",
        "[[1]]\n\n",
        "> ",
        "dsplots[[6]]",
        "[[1]]\n\n",
        "> ",
        "summary(model[[1]])$spec_pars[1,1]",
        "Error in summary(model[[1]])$spec_pars : \n  $ operator is invalid for atomic vectors\n",
        "> ",
        "summary(dout$model[[2]])$spec_pars[1,1]",
        "[1] 3.335704\n",
        "> ",
        "summary(dout$model[[2]])$spec_pars",
        "      Estimate Est.Error l-95% CI\nshape 3.335704 0.8370359 1.999239\n      u-95% CI     Rhat Bulk_ESS\nshape 5.188184 1.000228     3704\n      Tail_ESS\nshape     3155\n",
        "> ",
        "?nbinom",
        "No documentation for nbinom in specified packages and libraries:\nyou could try ??nbinom\n",
        "> ",
        "?pnbinom",
        "> ",
        "dsplots <- dout %>%",
        "+ ",
        "  group_by(ID) %>%",
        "+ ",
        "  with_groups({",
        "+ ",
        "    #Get shape param mean",
        "+ ",
        "    if (family == \"negbinomial\"){",
        "+ ",
        "      shape <- summary(model[[1]])$spec_pars[1,1]",
        "+ ",
        "    } else {",
        "+ ",
        "      shape <- NULL",
        "+ ",
        "    }",
        "+ ",
        "    ",
        "+ ",
        "    resids <- ds_resids(dat$y, ",
        "+ ",
        "                        #Note Mean estimate is in col 1 of ",
        "+ ",
        "                      #brms predict",
        "+ ",
        "                        predict(model[[1]])[,1], ",
        "+ ",
        "                        plot = FALSE, ",
        "+ ",
        "                        family = family, ",
        "+ ",
        "                        phis = 1/shape)",
        "+ ",
        "    dsdf <- bind_cols(dat, ",
        "+ ",
        "                      fitted = predict(model[[1]])[,1],",
        "+ ",
        "                      resid = resids)",
        "+ ",
        "    g1 <- ggplot(dsdf) + ",
        "+ ",
        "      aes(x = fitted, y = resid, color = x2) + ",
        "+ ",
        "      geom_point()  +",
        "+ ",
        "      ggtitle(paste_(form, family, prior))",
        "+ ",
        "    #save plot to file ",
        "+ ",
        "    # ggsave(g1, file = paste0(\"figures/model-\", ID, \".png\"))",
        "+ ",
        "    list(g1)",
        "+ ",
        "  })",
        "> ",
        "dsplots[[6]]",
        "[[1]]\n\n\nRestarting R session...\n\n"
    ],
    "type" : [
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        3,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        3,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        3,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        3,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        3,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        3,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2
    ]
}